{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a145b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams['image.cmap'] = 'jet'\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time as clock\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "from diffusion_equation import compute_solution\n",
    "from time import time\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941ed027-7b26-49c9-8f6a-72890b5ffbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a079a75f-cb74-4fa3-9208-89d3da846ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_the_gradient_from_loss(model, loss):\n",
    "    model.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    grads = []\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            grads.append(p.grad.detach().cpu().numpy().reshape(-1))\n",
    "    grad_flat = np.concatenate(grads)\n",
    "    return grad_flat\n",
    "\n",
    "def orthogonalize(v1, v2):\n",
    "    dot = np.dot(v1, v2)\n",
    "    proj = dot / (np.dot(v1, v1) + 1e-6) * v1\n",
    "    return v2 - proj\n",
    "\n",
    "def compute_weights_grad_orthogonal_autograd(model, loss_ic, loss_pde, loss_data, kappa=5.0, eps=1e-6):\n",
    "    grad_ic   = flat_the_gradient_from_loss(model, loss_ic)\n",
    "    grad_pde  = flat_the_gradient_from_loss(model, loss_pde)\n",
    "    grad_data = flat_the_gradient_from_loss(model, loss_data)\n",
    "\n",
    "    grad_pde_orth = orthogonalize(grad_ic, grad_pde)\n",
    "    grad_data_orth = orthogonalize(grad_ic, grad_data)\n",
    "    grad_data_orth = orthogonalize(grad_pde_orth, grad_data_orth)\n",
    "\n",
    "    lv_ic = loss_ic.detach().cpu().numpy()\n",
    "    lv_pde = loss_pde.detach().cpu().numpy()\n",
    "    lv_data = loss_data.detach().cpu().numpy()\n",
    "\n",
    "    w_ic = 1.0\n",
    "    w_pde = np.exp(-kappa * lv_ic) * np.linalg.norm(grad_pde_orth)\n",
    "    w_data = np.exp(-kappa * max(lv_ic, lv_pde)) * np.linalg.norm(grad_data_orth)\n",
    "    w_sum = w_ic + w_pde + w_data + eps\n",
    "    w_ic /= w_sum\n",
    "    w_pde /= w_sum\n",
    "    w_data /= w_sum\n",
    "\n",
    "\n",
    "    # model.zero_grad()\n",
    "\n",
    "    return w_ic, w_pde, w_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ecca3",
   "metadata": {},
   "source": [
    "# Getting data from simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b38cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of simulator\n",
    "# and parametrs of reservouir\n",
    "perm = np.load('perm.npy')\n",
    "nx0, nx1 = perm.shape\n",
    "nx2 = 1\n",
    "perm = np.reshape(perm, (nx0, nx1, nx2))\n",
    "poro = 0.1 + np.zeros((nx0, nx1, nx2))\n",
    "\n",
    "dx0 = 1.0 / nx0\n",
    "dx1 = 1.0 / nx1\n",
    "dx2 = 1.0 / nx2\n",
    "\n",
    "pwat = 2.0\n",
    "poil = 4.0\n",
    "vr = 0.3\n",
    "kwat = 1.0\n",
    "koil = 0.3\n",
    "\n",
    "pmin = 0.0\n",
    "pmax = 1.0\n",
    "\n",
    "niter = 5000\n",
    "\n",
    "t_final = 3.0\n",
    "dt = t_final / niter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8846e8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx0, nx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f49e2252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 4.0, 1.0, 0.3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwat, poil, kwat, koil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9274286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_num = 200\n",
    "# niter = 100\n",
    "# t_final = 3.0\n",
    "# dt = t_final / niter\n",
    "\n",
    "# # press, swat, soil, \n",
    "# # pwat, poil, kwat, koil\n",
    "\n",
    "# sim_data = np.zeros((niter * sample_num, 3))\n",
    "\n",
    "# x_points = np.zeros((niter * sample_num))\n",
    "# y_points = np.zeros((niter * sample_num))\n",
    "# t_points = np.zeros((niter * sample_num))\n",
    "\n",
    "# pwats = np.zeros((niter * sample_num))\n",
    "# poils = np.zeros((niter * sample_num))\n",
    "# kwats = np.zeros((niter * sample_num))\n",
    "# koils = np.zeros((niter * sample_num))\n",
    "\n",
    "# vr = 1 / 3\n",
    "\n",
    "# for sample_index in trange(1, sample_num + 1):\n",
    "    \n",
    "#     pwat = 2 + np.random.random() * 4\n",
    "#     poil = 2 + np.random.random() * 4\n",
    "#     kwat = 0.5 * np.random.random() + 0.5\n",
    "#     koil = 0.4 * np.random.random() + 0.1\n",
    "    \n",
    "# #     pres, swat, soil = compute_solution(perm, poro,\n",
    "# #                                         dx0, dx1, dx2, t_final, niter,\n",
    "# #                                         pwat, kwat, poil, koil, vr,\n",
    "# #                                         pmin=0.0, pmax=1.0)\n",
    "        \n",
    "#     x_list = np.random.randint(size=niter, low=0, high=64)\n",
    "#     y_list = np.random.randint(size=niter, low=0, high=64)\n",
    "#     dt_n = np.random.randint(size=niter, low=0, high=niter)\n",
    "    \n",
    "#     x_points[(sample_index - 1) * niter: sample_index * niter] = x_list\n",
    "#     y_points[(sample_index - 1) * niter: sample_index * niter] = y_list\n",
    "#     t_points[(sample_index - 1) * niter: sample_index * niter] = dt_n\n",
    "    \n",
    "#     pwats[(sample_index - 1) * niter: sample_index * niter] = pwat\n",
    "#     poils[(sample_index - 1) * niter: sample_index * niter] = poil\n",
    "#     kwats[(sample_index - 1) * niter: sample_index * niter] = kwat\n",
    "#     koils[(sample_index - 1) * niter: sample_index * niter] = koil\n",
    "\n",
    "#     for i in range(niter):\n",
    "#         sim_data[i + (sample_index - 1) * niter, 0] = pres[x_list[i], y_list[i], 0, dt_n[i]]\n",
    "#         sim_data[i + (sample_index - 1) * niter, 1] = swat[x_list[i], y_list[i], 0, dt_n[i]]\n",
    "#         sim_data[i + (sample_index - 1) * niter, 2] = soil[x_list[i], y_list[i], 0, dt_n[i]]\n",
    "        \n",
    "# N = niter\n",
    "\n",
    "# np.savetxt(f\"data_100_nonlinear/sim_{N}.txt\", sim_data)\n",
    "\n",
    "# np.savetxt(f\"data_100_nonlinear/x_{N}.txt\", x_points)\n",
    "# np.savetxt(f\"data_100_nonlinear/y_{N}.txt\", y_points)\n",
    "# np.savetxt(f\"data_100_nonlinear/t_{N}.txt\", t_points)\n",
    "\n",
    "# np.savetxt(f\"data_100_nonlinear/pwat_{N}.txt\", pwats)\n",
    "# np.savetxt(f\"data_100_nonlinear/poil_{N}.txt\", poils)\n",
    "# np.savetxt(f\"data_100_nonlinear/kwat_{N}.txt\", kwats)\n",
    "# np.savetxt(f\"data_100_nonlinear/koil_{N}.txt\", koils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d592b41",
   "metadata": {},
   "source": [
    "# Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "623e8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_nidexes = np.random.randint(0, 30000, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76be333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_data: pres, swat, soil\n",
    "\n",
    "sim_data = np.loadtxt(\"data_100_nonlinear/sim_100.txt\", dtype=np.float32)[sim_nidexes]\n",
    "\n",
    "x_list = np.loadtxt(\"data_100_nonlinear/x_100.txt\", dtype=np.float32)[sim_nidexes]\n",
    "y_list = np.loadtxt(\"data_100_nonlinear/y_100.txt\", dtype=np.float32)[sim_nidexes]\n",
    "t_list = np.loadtxt(\"data_100_nonlinear/t_100.txt\", dtype=np.float32)[sim_nidexes]\n",
    "\n",
    "pwat_list = np.loadtxt(\"data_100_nonlinear/pwat_100.txt\", dtype=np.float32)[sim_nidexes]\n",
    "poil_list = np.loadtxt(\"data_100_nonlinear/poil_100.txt\", dtype=np.float32)[sim_nidexes]\n",
    "kwat_list = np.loadtxt(\"data_100_nonlinear/kwat_100.txt\", dtype=np.float32)[sim_nidexes]\n",
    "koil_list = np.loadtxt(\"data_100_nonlinear/koil_100.txt\", dtype=np.float32)[sim_nidexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc59e55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba398e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa420d",
   "metadata": {},
   "source": [
    "# Convert to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8084df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data = torch.tensor(sim_data).requires_grad_(True)\n",
    "\n",
    "x = torch.tensor(x_list * dx0).requires_grad_(True)\n",
    "y = torch.tensor(y_list * dx1).requires_grad_(True)\n",
    "t = torch.tensor(t_list * dt).requires_grad_(True)\n",
    "\n",
    "\n",
    "pwat = torch.tensor(pwat_list)\n",
    "poil = torch.tensor(poil_list)\n",
    "kwat = torch.tensor(kwat_list)\n",
    "koil = torch.tensor(koil_list)\n",
    "\n",
    "points = torch.stack((t, x, y, pwat, poil, kwat, koil), -1).requires_grad_(True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af34b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c4fcb",
   "metadata": {},
   "source": [
    "# Boundary points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4f69b7-ec9d-46c6-8e48-69d811e6d1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>pwat</th>\n",
       "      <th>poil</th>\n",
       "      <th>kwat</th>\n",
       "      <th>koil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029575</td>\n",
       "      <td>0.489966</td>\n",
       "      <td>0.492978</td>\n",
       "      <td>2.016249</td>\n",
       "      <td>3.969793</td>\n",
       "      <td>15.371053</td>\n",
       "      <td>15.077959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.017203</td>\n",
       "      <td>0.289651</td>\n",
       "      <td>0.285861</td>\n",
       "      <td>0.278935</td>\n",
       "      <td>0.559568</td>\n",
       "      <td>8.421176</td>\n",
       "      <td>8.188314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.501701</td>\n",
       "      <td>3.005682</td>\n",
       "      <td>1.204434</td>\n",
       "      <td>1.009385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.772725</td>\n",
       "      <td>3.494541</td>\n",
       "      <td>8.434031</td>\n",
       "      <td>8.687350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.041989</td>\n",
       "      <td>3.944211</td>\n",
       "      <td>15.769983</td>\n",
       "      <td>14.533257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>2.266103</td>\n",
       "      <td>4.430557</td>\n",
       "      <td>22.243668</td>\n",
       "      <td>21.562063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>2.495593</td>\n",
       "      <td>4.994729</td>\n",
       "      <td>29.771601</td>\n",
       "      <td>29.902391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t            x            y         pwat         poil  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      0.029575     0.489966     0.492978     2.016249     3.969793   \n",
       "std       0.017203     0.289651     0.285861     0.278935     0.559568   \n",
       "min       0.000000     0.000000     0.000000     1.501701     3.005682   \n",
       "25%       0.015000     0.250000     0.250000     1.772725     3.494541   \n",
       "50%       0.029400     0.484375     0.500000     2.041989     3.944211   \n",
       "75%       0.044400     0.734375     0.734375     2.266103     4.430557   \n",
       "max       0.059400     0.984375     0.984375     2.495593     4.994729   \n",
       "\n",
       "              kwat         koil  \n",
       "count  5000.000000  5000.000000  \n",
       "mean     15.371053    15.077959  \n",
       "std       8.421176     8.188314  \n",
       "min       1.204434     1.009385  \n",
       "25%       8.434031     8.687350  \n",
       "50%      15.769983    14.533257  \n",
       "75%      22.243668    21.562063  \n",
       "max      29.771601    29.902391  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=points.cpu().detach().numpy(), columns=['t', 'x', 'y', 'pwat', 'poil', 'kwat', 'koil']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd3069c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres0_x1_points = torch.stack(\n",
    "    (t, torch.zeros_like(x), y, pwat, poil, kwat, koil), -1).requires_grad_(True).to(DEVICE)\n",
    "\n",
    "pres1_x1_points = torch.stack(\n",
    "    (t, torch.ones_like(x), y, pwat, poil, kwat, koil), -1).requires_grad_(True).to(DEVICE)\n",
    "\n",
    "swat0_x1_points = torch.stack(\n",
    "    (torch.zeros_like(t), x, y, pwat, poil, kwat, koil), -1).requires_grad_(True).to(DEVICE)\n",
    "\n",
    "soil0_x1_points = torch.stack(\n",
    "    (torch.zeros_like(t), x, y, pwat, poil, kwat, koil), -1).requires_grad_(True).to(DEVICE)\n",
    "\n",
    "u0_x2_points = torch.stack(\n",
    "    (t, x, torch.zeros_like(y), pwat, poil, kwat, koil), -1).requires_grad_(True).to(DEVICE)\n",
    "\n",
    "u1_x2_points = torch.stack(\n",
    "    (t, x, torch.ones_like(y), pwat, poil, kwat, koil), -1).requires_grad_(True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda8443",
   "metadata": {},
   "source": [
    "# Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c74f1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define the class PINN\n",
    "# ## input = (x, y, t, pwat, poil, pwat, kwat)\n",
    "# class pinn_model(nn.Module):\n",
    "#     def __init__(self, input_layer = 7, hidden_layer = 128, number_layers = 16, output_layer = 7):\n",
    "#         super().__init__()\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.relu6 = nn.ReLU6()\n",
    "        \n",
    "#         self.fcs = nn.Sequential(*\n",
    "#             [\n",
    "#                 nn.Linear(input_layer, hidden_layer),\n",
    "#                 nn.BatchNorm1d(hidden_layer),\n",
    "#                 nn.ReLU()\n",
    "#             ]\n",
    "#         )\n",
    "        \n",
    "#         self.fch = nn.Sequential(*\n",
    "#             [\n",
    "#                 nn.Sequential(*\n",
    "#                     [\n",
    "#                         nn.Linear(hidden_layer, hidden_layer),\n",
    "#                         nn.Dropout(p=0.2),\n",
    "#                         nn.ReLU()\n",
    "#                     ]\n",
    "#                 ) for _ in range(number_layers - 1)\n",
    "#             ]\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         function for updating neural network\n",
    "        \n",
    "#         return:\n",
    "#             x - vector (pres\n",
    "#                         soil\n",
    "#                         swat\n",
    "#                         uoil_x,  \n",
    "#                         uoil_y,\n",
    "#                         uwat_x,  \n",
    "#                         uwat_y)\n",
    "#         \"\"\"\n",
    "        \n",
    "#         x = self.fcs(x)\n",
    "#         x = self.fch(x)     \n",
    "#         # x = self.fce(x)\n",
    "#         x = self.relu(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "class pinn_model(nn.Module):\n",
    "    def __init__(self, input_layer=7, hidden_layer=64, number_layers=5, output_layer=7):\n",
    "        super(pinn_model, self).__init__()\n",
    "        \n",
    "        # Simplified model with fewer layers and smaller hidden layer size\n",
    "        self.hidden_layer = hidden_layer\n",
    "        \n",
    "        # Initial layer\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(input_layer, hidden_layer),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Reduced number of hidden layers\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_layer, hidden_layer),\n",
    "                nn.ReLU()  # Removed batch normalization and dropout to reduce complexity\n",
    "            )\n",
    "            for _ in range(number_layers - 1)\n",
    "        ])\n",
    "        \n",
    "        # Output layer (use Softplus to ensure strictly positive outputs)\n",
    "        self.fc_out = nn.Linear(hidden_layer, output_layer)\n",
    "        \n",
    "        # Weight initialization (Xavier Initialization for better convergence)\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initializes the weights using Xavier Initialization for better convergence.\"\"\"\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)  # Xavier for better weight scaling\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, input_layer)\n",
    "        \n",
    "        Returns:\n",
    "            x: Output tensor of shape (batch_size, output_layer)\n",
    "        \"\"\"\n",
    "        # Pass through the first layer\n",
    "        x = self.fcs(x)\n",
    "        \n",
    "        # Pass through hidden layers (no skip connections for simplicity)\n",
    "        for layer in self.fch:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Final output layer (using Softplus to enforce positive output)\n",
    "        x = self.fc_out(x)\n",
    "        x = F.softplus(x)  # Ensuring the output is strictly positive\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524917b",
   "metadata": {},
   "source": [
    "draft\n",
    "\n",
    "<!-- \n",
    "\n",
    "# Differentiail equations, Loss function difinition\n",
    "\n",
    "$$k_{water} = 1, k_{oil} = 0.3$$\n",
    "$$x = (x_1, x_2)$$\n",
    "$$ \\phi(x) = 0.1 (poro)\\\\\n",
    "k(x) = 1 (perm)$$\n",
    "\n",
    "#### System of equation:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "        r_1(t, x) = 0.1 \\frac{\\partial s_{\\text{water}}(t, x)}{\\partial t} + div(u_{water}) = 0 \\\\\n",
    "        r_2(t, x) = 0.1 \\frac{\\partial s_{\\text{oil}}(t, x)}{\\partial t} + div(u_{oil}) = 0 \\\\\n",
    "        r_{3,x_1}(t, x) = u_{\\text{water},x_1} + \\frac{\\partial P(t, x)}{\\partial x_1} = 0 \\\\\n",
    "        r_{3,x_2}(t, x) = u_{\\text{water},x_2} + \\frac{\\partial P(t, x)}{\\partial x_2} = 0 \\\\\n",
    "        r_{4, x_1}(t, x) = u_{\\text{oil},x_1} + 0.1 \\frac{\\partial P(t, x)}{\\partial x_1} = 0 \\\\\n",
    "        r_{4, x_2}(t, x) = u_{\\text{oil},x_2} + 0.1 \\frac{\\partial P(t, x)}{\\partial x_2} = 0 \\\\\n",
    "        r_5(t, x) = s_{\\text{water}}(t, x) + s_{\\text{oil}}(t, x) - 1 = 0 \\\\\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "#### Boundary condition\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "        P(t, (0, x_2)) = (1, 1) \\\\\n",
    "        P(t, (1, x_2)) = (0, 0) \\\\\n",
    "        s_{\\text{water}}(0, x) = (0, 0) \\\\\n",
    "        s_{\\text{oil}}(0, x) = (1, 1) \\\\\n",
    "        u_{water/ oil}^{x_2}(t, x)\\big|_{x_2=0} = u_{water/ oil}^{x_2}(t, x)\\big|_{x_2=1} = 0\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "#### Loss function:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\label{eq:loss_term_0}\n",
    "    \\mathcal{R}_0(t, x) = r_1(t, x)^2 + r_2(t, x)^2 + r_3(t, x)^2 + r_4(t, x)^2 + r_5(t, x)^2\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\label{eq:loss_term_1}\n",
    "    \\mathcal{R}_1(t, x) = \\big(p(t, 0) - 1.0\\big)^2 + \\big(p(t, 1) - 0.0 \\big)^2 + \\big( s_{\\text{oil}}(0, x) - 1.0 \\big)^2 + \\big( s_{\\text{water}}(0, x) - 0.0 \\big)^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{split}\n",
    "        \\mathcal{R}_2(t, x) = \\big( p_{\\text{neural network}}(t, x) - p_{\\text{simulation}}(t, x)\\big)^2 + \\\\ + \\big( s_{\\text{water, neural network}}(t, x) - s_{\\text{water, simulation}}(t, x)\\big)^2 + \\\\ + \\big( s_{\\text{oil, neural network}}(t, x) - s_{\\text{oil, simulation}}(t, x)\\big)^2\n",
    "\\end{split}\n",
    "\n",
    "#### Resultant function:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\label{eq:loss_final}\n",
    "    \\mathcal{L} = w_0 \\frac{1}{N} \\mathcal{R}_0(t_i, x_i) + w_1 \\frac{1}{N} \\mathcal{R}_1(t_i, x_i) + w_2 \\frac{1}{N} \\mathcal{R}_2(t_i, x_i)\n",
    "\\end{equation} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba81ca",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e3351c3-4629-4b54-8851-13a404859b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                               | 2/10000 [00:00<1:01:31,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.1990e+01, Loss0: 1.1991e+01, Loss1: 2.9589e+00, Loss2: 2.4728e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                               | 22/10000 [00:03<29:07,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 1.0158e-01, Loss0: 7.4791e-02, Loss1: 5.1849e-01, Loss2: 1.3152e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                               | 42/10000 [00:07<23:16,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 2.0251e-02, Loss0: 8.5095e-03, Loss1: 5.0346e-01, Loss2: 1.1815e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                                               | 62/10000 [00:09<23:10,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 1.0934e-02, Loss0: 3.2906e-03, Loss1: 4.9116e-01, Loss2: 1.1515e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                               | 82/10000 [00:12<23:06,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss: 3.5649e-03, Loss0: 1.9691e-03, Loss1: 4.7752e-01, Loss2: 1.1219e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                             | 102/10000 [00:15<23:09,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 3.9389e-03, Loss0: 1.4565e-03, Loss1: 4.4415e-01, Loss2: 1.0588e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                             | 122/10000 [00:18<22:53,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120, Loss: 2.3588e-02, Loss0: 1.4145e-03, Loss1: 3.1866e-01, Loss2: 8.1824e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▌                                                                                                             | 142/10000 [00:21<22:44,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140, Loss: 2.7330e-02, Loss0: 1.6707e-03, Loss1: 5.4969e-01, Loss2: 1.9750e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                                             | 162/10000 [00:23<22:19,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Loss: 3.0457e-03, Loss0: 2.1275e-03, Loss1: 9.7464e-01, Loss2: 3.4672e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                             | 182/10000 [00:26<22:46,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Loss: 3.6282e-02, Loss0: 5.3833e-03, Loss1: 4.8898e-01, Loss2: 1.2893e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                                            | 202/10000 [00:29<22:34,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 2.2232e-02, Loss0: 3.7422e-03, Loss1: 4.2889e-01, Loss2: 1.0642e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▍                                                                                                            | 222/10000 [00:32<22:11,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220, Loss: 1.9413e-02, Loss0: 2.5836e-03, Loss1: 3.0383e-01, Loss2: 7.8910e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▋                                                                                                            | 242/10000 [00:35<22:36,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240, Loss: 1.8751e-02, Loss0: 3.0486e-03, Loss1: 8.6138e-02, Loss2: 3.3557e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▉                                                                                                            | 262/10000 [00:37<22:05,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260, Loss: 1.9513e-02, Loss0: 3.0510e-03, Loss1: 9.0967e-02, Loss2: 3.3652e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▏                                                                                                           | 282/10000 [00:40<24:33,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280, Loss: 8.6555e-03, Loss0: 2.9958e-03, Loss1: 4.6324e-02, Loss2: 1.6355e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▎                                                                                                           | 302/10000 [00:43<23:17,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, Loss: 8.4839e-03, Loss0: 2.2763e-03, Loss1: 2.2472e-02, Loss2: 1.3142e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▌                                                                                                           | 322/10000 [00:46<22:35,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320, Loss: 4.0716e-03, Loss0: 1.8519e-03, Loss1: 1.9588e-02, Loss2: 9.5787e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                           | 342/10000 [00:49<22:43,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, Loss: 2.2975e-03, Loss0: 1.5415e-03, Loss1: 1.6896e-02, Loss2: 8.3889e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                           | 362/10000 [00:52<22:32,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Loss: 1.9229e-03, Loss0: 1.3457e-03, Loss1: 1.7817e-02, Loss2: 7.5267e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▏                                                                                                          | 382/10000 [00:55<22:28,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380, Loss: 1.6044e-03, Loss0: 1.1814e-03, Loss1: 1.6114e-02, Loss2: 6.9846e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▍                                                                                                          | 402/10000 [00:57<22:43,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, Loss: 1.4445e-03, Loss0: 1.0612e-03, Loss1: 1.4951e-02, Loss2: 6.5523e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▋                                                                                                          | 422/10000 [01:00<22:44,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 420, Loss: 1.3015e-03, Loss0: 9.5516e-04, Loss1: 1.3778e-02, Loss2: 6.1364e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▉                                                                                                          | 442/10000 [01:03<22:30,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 440, Loss: 1.1355e-03, Loss0: 8.6201e-04, Loss1: 1.2767e-02, Loss2: 5.7731e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▏                                                                                                         | 462/10000 [01:06<22:28,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 460, Loss: 1.0346e-03, Loss0: 7.9041e-04, Loss1: 1.1797e-02, Loss2: 5.4459e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▎                                                                                                         | 482/10000 [01:09<22:33,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480, Loss: 9.6392e-04, Loss0: 7.3542e-04, Loss1: 1.0827e-02, Loss2: 5.1354e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▌                                                                                                         | 502/10000 [01:12<22:20,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Loss: 8.9534e-04, Loss0: 6.8737e-04, Loss1: 9.8783e-03, Loss2: 4.8680e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▊                                                                                                         | 522/10000 [01:15<22:12,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 520, Loss: 8.0759e-04, Loss0: 6.4661e-04, Loss1: 8.5517e-03, Loss2: 4.6349e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████                                                                                                         | 542/10000 [01:17<22:05,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 540, Loss: 7.6499e-04, Loss0: 6.1153e-04, Loss1: 7.7178e-03, Loss2: 4.4199e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▏                                                                                                        | 562/10000 [01:20<22:20,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 560, Loss: 7.1884e-04, Loss0: 5.8279e-04, Loss1: 7.0097e-03, Loss2: 4.2328e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▍                                                                                                        | 582/10000 [01:23<22:18,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 580, Loss: 6.6133e-04, Loss0: 5.5583e-04, Loss1: 6.3003e-03, Loss2: 4.0736e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▋                                                                                                        | 602/10000 [01:26<22:20,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, Loss: 7.0953e-04, Loss0: 5.3152e-04, Loss1: 5.7063e-03, Loss2: 3.9348e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▉                                                                                                        | 622/10000 [01:29<22:11,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 620, Loss: 5.9514e-04, Loss0: 5.0819e-04, Loss1: 5.1783e-03, Loss2: 3.8134e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████▏                                                                                                       | 642/10000 [01:32<22:11,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 640, Loss: 5.7173e-04, Loss0: 4.8613e-04, Loss1: 4.7787e-03, Loss2: 3.7079e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▎                                                                                                       | 662/10000 [01:35<22:49,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 660, Loss: 5.3342e-04, Loss0: 4.6577e-04, Loss1: 4.4611e-03, Loss2: 3.6179e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▌                                                                                                       | 682/10000 [01:38<22:13,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 680, Loss: 5.1223e-04, Loss0: 4.4588e-04, Loss1: 4.2210e-03, Loss2: 3.5427e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▊                                                                                                       | 702/10000 [01:41<22:39,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700, Loss: 4.8698e-04, Loss0: 4.2791e-04, Loss1: 4.0230e-03, Loss2: 3.4747e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████                                                                                                       | 722/10000 [01:44<21:58,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 720, Loss: 4.7633e-04, Loss0: 4.1238e-04, Loss1: 3.8542e-03, Loss2: 3.4093e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████▏                                                                                                      | 742/10000 [01:46<21:35,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 740, Loss: 4.5442e-04, Loss0: 3.9660e-04, Loss1: 3.7308e-03, Loss2: 3.3463e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████▍                                                                                                      | 762/10000 [01:49<21:51,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 760, Loss: 4.5757e-04, Loss0: 3.8194e-04, Loss1: 3.5571e-03, Loss2: 3.2867e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████▋                                                                                                      | 782/10000 [01:52<22:16,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 780, Loss: 4.1207e-04, Loss0: 3.6672e-04, Loss1: 3.4301e-03, Loss2: 3.2317e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████▉                                                                                                      | 802/10000 [01:55<22:03,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 800, Loss: 3.9963e-04, Loss0: 3.5253e-04, Loss1: 3.3074e-03, Loss2: 3.1798e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████                                                                                                      | 822/10000 [01:58<21:42,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 820, Loss: 3.8241e-04, Loss0: 3.3974e-04, Loss1: 3.2094e-03, Loss2: 3.1272e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████▎                                                                                                     | 842/10000 [02:01<21:53,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 840, Loss: 3.6939e-04, Loss0: 3.2765e-04, Loss1: 3.1317e-03, Loss2: 3.0738e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████▌                                                                                                     | 862/10000 [02:04<21:43,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 860, Loss: 3.5275e-04, Loss0: 3.1416e-04, Loss1: 2.9980e-03, Loss2: 3.0245e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████▊                                                                                                     | 882/10000 [02:06<21:53,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 880, Loss: 3.3484e-04, Loss0: 3.0104e-04, Loss1: 2.8727e-03, Loss2: 2.9796e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████                                                                                                     | 902/10000 [02:09<21:43,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 900, Loss: 3.1986e-04, Loss0: 2.8902e-04, Loss1: 2.7593e-03, Loss2: 2.9396e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████▏                                                                                                    | 922/10000 [02:12<21:30,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920, Loss: 3.1217e-04, Loss0: 2.7760e-04, Loss1: 2.6687e-03, Loss2: 2.9032e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████▍                                                                                                    | 942/10000 [02:15<21:37,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 940, Loss: 2.9682e-04, Loss0: 2.6666e-04, Loss1: 2.5924e-03, Loss2: 2.8680e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▋                                                                                                    | 962/10000 [02:18<21:31,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 960, Loss: 2.8484e-04, Loss0: 2.5605e-04, Loss1: 2.5315e-03, Loss2: 2.8334e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▉                                                                                                    | 982/10000 [02:21<21:18,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 980, Loss: 3.1391e-04, Loss0: 2.4673e-04, Loss1: 2.4496e-03, Loss2: 2.7996e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████                                                                                                   | 1002/10000 [02:24<21:15,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Loss: 3.6007e-04, Loss0: 2.3874e-04, Loss1: 2.3642e-03, Loss2: 2.7687e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▏                                                                                                  | 1022/10000 [02:26<21:15,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1020, Loss: 4.3429e-04, Loss0: 2.3487e-04, Loss1: 2.2422e-03, Loss2: 2.7463e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▍                                                                                                  | 1042/10000 [02:29<21:09,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1040, Loss: 3.1776e-04, Loss0: 2.2093e-04, Loss1: 2.2231e-03, Loss2: 2.7049e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████████▋                                                                                                  | 1062/10000 [02:32<20:45,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1060, Loss: 3.3463e-04, Loss0: 2.1445e-04, Loss1: 2.1058e-03, Loss2: 2.6797e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████████▉                                                                                                  | 1082/10000 [02:35<20:49,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1080, Loss: 3.7372e-03, Loss0: 7.4303e-04, Loss1: 6.2870e-03, Loss2: 5.1877e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████                                                                                                  | 1102/10000 [02:38<20:52,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1100, Loss: 1.7331e-03, Loss0: 5.2466e-04, Loss1: 2.9398e-03, Loss2: 3.7879e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▎                                                                                                 | 1122/10000 [02:41<20:46,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1120, Loss: 7.6001e-04, Loss0: 3.0992e-04, Loss1: 2.1178e-03, Loss2: 2.9368e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▌                                                                                                 | 1142/10000 [02:43<20:40,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1140, Loss: 3.9764e-04, Loss0: 2.5600e-04, Loss1: 2.1262e-03, Loss2: 2.7991e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████▊                                                                                                 | 1162/10000 [02:46<20:44,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1160, Loss: 3.0354e-04, Loss0: 2.3146e-04, Loss1: 2.1413e-03, Loss2: 2.7400e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████                                                                                                 | 1182/10000 [02:49<20:42,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1180, Loss: 2.5435e-04, Loss0: 2.1813e-04, Loss1: 2.1622e-03, Loss2: 2.6999e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████▏                                                                                                | 1202/10000 [02:52<20:49,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1200, Loss: 2.3267e-04, Loss0: 2.0806e-04, Loss1: 2.1430e-03, Loss2: 2.6734e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████▍                                                                                                | 1222/10000 [02:55<20:48,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1220, Loss: 2.1934e-04, Loss0: 1.9762e-04, Loss1: 2.1142e-03, Loss2: 2.6505e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████▋                                                                                                | 1242/10000 [02:58<20:52,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1240, Loss: 2.0900e-04, Loss0: 1.8833e-04, Loss1: 2.0766e-03, Loss2: 2.6309e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████████▉                                                                                                | 1262/10000 [03:00<20:57,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1260, Loss: 2.0012e-04, Loss0: 1.8009e-04, Loss1: 2.0466e-03, Loss2: 2.6125e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████████                                                                                                | 1282/10000 [03:03<20:50,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1280, Loss: 1.9258e-04, Loss0: 1.7287e-04, Loss1: 2.0192e-03, Loss2: 2.5941e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████████▎                                                                                               | 1302/10000 [03:06<20:42,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1300, Loss: 1.8514e-04, Loss0: 1.6600e-04, Loss1: 2.0008e-03, Loss2: 2.5763e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████████▌                                                                                               | 1322/10000 [03:10<24:58,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1320, Loss: 1.7794e-04, Loss0: 1.5969e-04, Loss1: 1.9860e-03, Loss2: 2.5586e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████████▊                                                                                               | 1342/10000 [03:13<20:47,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340, Loss: 1.7145e-04, Loss0: 1.5378e-04, Loss1: 1.9718e-03, Loss2: 2.5415e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████▉                                                                                               | 1362/10000 [03:16<20:45,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1360, Loss: 1.6482e-04, Loss0: 1.4777e-04, Loss1: 1.9510e-03, Loss2: 2.5256e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▏                                                                                              | 1382/10000 [03:18<20:31,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1380, Loss: 1.5841e-04, Loss0: 1.4199e-04, Loss1: 1.9281e-03, Loss2: 2.5106e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▍                                                                                              | 1402/10000 [03:21<20:41,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1400, Loss: 1.5309e-04, Loss0: 1.3697e-04, Loss1: 1.9108e-03, Loss2: 2.4958e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▋                                                                                              | 1422/10000 [03:24<20:29,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1420, Loss: 1.4821e-04, Loss0: 1.3237e-04, Loss1: 1.8939e-03, Loss2: 2.4814e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▊                                                                                              | 1442/10000 [03:27<22:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1440, Loss: 1.4331e-04, Loss0: 1.2801e-04, Loss1: 1.8784e-03, Loss2: 2.4672e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████                                                                                              | 1462/10000 [03:30<20:49,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1460, Loss: 1.3841e-04, Loss0: 1.2365e-04, Loss1: 1.8600e-03, Loss2: 2.4536e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████▎                                                                                             | 1482/10000 [03:34<24:31,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1480, Loss: 1.3384e-04, Loss0: 1.1933e-04, Loss1: 1.8381e-03, Loss2: 2.4409e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████▌                                                                                             | 1502/10000 [03:37<20:33,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1500, Loss: 1.2944e-04, Loss0: 1.1544e-04, Loss1: 1.8196e-03, Loss2: 2.4284e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████▋                                                                                             | 1522/10000 [03:40<20:21,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1520, Loss: 1.2501e-04, Loss0: 1.1154e-04, Loss1: 1.7997e-03, Loss2: 2.4166e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████▉                                                                                             | 1542/10000 [03:43<22:02,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1540, Loss: 1.2081e-04, Loss0: 1.0757e-04, Loss1: 1.7813e-03, Loss2: 2.4056e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████▏                                                                                            | 1562/10000 [03:46<25:59,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1560, Loss: 1.1678e-04, Loss0: 1.0398e-04, Loss1: 1.7646e-03, Loss2: 2.3947e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████▍                                                                                            | 1582/10000 [03:49<20:38,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1580, Loss: 1.1291e-04, Loss0: 1.0054e-04, Loss1: 1.7517e-03, Loss2: 2.3842e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████▌                                                                                            | 1602/10000 [03:52<20:35,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss: 1.0925e-04, Loss0: 9.7254e-05, Loss1: 1.7410e-03, Loss2: 2.3741e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████▊                                                                                            | 1622/10000 [03:55<19:44,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1620, Loss: 1.0603e-04, Loss0: 9.4152e-05, Loss1: 1.7281e-03, Loss2: 2.3645e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████                                                                                            | 1642/10000 [03:58<20:03,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1640, Loss: 1.0305e-04, Loss0: 9.1377e-05, Loss1: 1.7147e-03, Loss2: 2.3548e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████▎                                                                                           | 1662/10000 [04:00<19:59,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1660, Loss: 9.9445e-05, Loss0: 8.8498e-05, Loss1: 1.6987e-03, Loss2: 2.3456e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████▌                                                                                           | 1682/10000 [04:03<19:59,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1680, Loss: 9.6090e-05, Loss0: 8.5678e-05, Loss1: 1.6851e-03, Loss2: 2.3370e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████▋                                                                                           | 1702/10000 [04:06<19:57,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1700, Loss: 9.3725e-05, Loss0: 8.3084e-05, Loss1: 1.6766e-03, Loss2: 2.3287e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████▉                                                                                           | 1722/10000 [04:09<19:43,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1720, Loss: 9.0586e-05, Loss0: 8.0580e-05, Loss1: 1.6670e-03, Loss2: 2.3206e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████▏                                                                                          | 1742/10000 [04:12<20:31,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1740, Loss: 9.3308e-05, Loss0: 7.8239e-05, Loss1: 1.6571e-03, Loss2: 2.3128e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████▍                                                                                          | 1762/10000 [04:15<19:36,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1760, Loss: 2.0658e-04, Loss0: 8.1475e-05, Loss1: 1.6299e-03, Loss2: 2.3116e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████▌                                                                                          | 1782/10000 [04:18<19:08,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1780, Loss: 4.8264e-03, Loss0: 3.0509e-03, Loss1: 5.8439e-03, Loss2: 8.7072e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████▊                                                                                          | 1802/10000 [04:21<19:13,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1800, Loss: 2.2817e-02, Loss0: 1.9001e-03, Loss1: 5.7508e-02, Loss2: 2.3739e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████                                                                                          | 1822/10000 [04:23<19:15,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1820, Loss: 3.6381e-03, Loss0: 1.1381e-03, Loss1: 1.3188e-02, Loss2: 6.7369e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▎                                                                                         | 1842/10000 [04:26<19:02,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1840, Loss: 1.4335e-03, Loss0: 7.2293e-04, Loss1: 3.5259e-03, Loss2: 3.6276e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████▍                                                                                         | 1862/10000 [04:29<18:58,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1860, Loss: 5.5817e-04, Loss0: 4.6358e-04, Loss1: 1.7691e-03, Loss2: 2.7676e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████▋                                                                                         | 1882/10000 [04:32<19:11,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1880, Loss: 3.9756e-04, Loss0: 3.3425e-04, Loss1: 1.6080e-03, Loss2: 2.6507e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████▉                                                                                         | 1902/10000 [04:35<18:56,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1900, Loss: 3.1314e-04, Loss0: 2.6666e-04, Loss1: 1.5702e-03, Loss2: 2.5774e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▏                                                                                        | 1922/10000 [04:37<18:48,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1920, Loss: 2.5721e-04, Loss0: 2.2454e-04, Loss1: 1.5165e-03, Loss2: 2.5305e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▎                                                                                        | 1942/10000 [04:40<18:50,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1940, Loss: 2.2281e-04, Loss0: 1.9678e-04, Loss1: 1.4884e-03, Loss2: 2.4946e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████▌                                                                                        | 1962/10000 [04:43<18:50,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1960, Loss: 2.0031e-04, Loss0: 1.7585e-04, Loss1: 1.4632e-03, Loss2: 2.4651e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████▊                                                                                        | 1982/10000 [04:46<18:40,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1980, Loss: 1.8171e-04, Loss0: 1.5994e-04, Loss1: 1.4420e-03, Loss2: 2.4392e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████                                                                                        | 2002/10000 [04:49<19:14,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000, Loss: 1.6684e-04, Loss0: 1.4716e-04, Loss1: 1.4208e-03, Loss2: 2.4165e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████▏                                                                                       | 2022/10000 [04:52<19:05,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2020, Loss: 1.5477e-04, Loss0: 1.3667e-04, Loss1: 1.4004e-03, Loss2: 2.3986e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████▍                                                                                       | 2042/10000 [04:54<18:56,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2040, Loss: 1.4499e-04, Loss0: 1.2802e-04, Loss1: 1.3861e-03, Loss2: 2.3826e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████████▋                                                                                       | 2062/10000 [04:57<18:50,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2060, Loss: 1.3672e-04, Loss0: 1.2051e-04, Loss1: 1.3738e-03, Loss2: 2.3676e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████████▉                                                                                       | 2082/10000 [05:00<18:51,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2080, Loss: 1.2912e-04, Loss0: 1.1382e-04, Loss1: 1.3577e-03, Loss2: 2.3531e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████                                                                                       | 2102/10000 [05:03<19:02,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2100, Loss: 1.2251e-04, Loss0: 1.0820e-04, Loss1: 1.3445e-03, Loss2: 2.3393e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████▎                                                                                      | 2122/10000 [05:06<18:59,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2120, Loss: 1.1686e-04, Loss0: 1.0321e-04, Loss1: 1.3337e-03, Loss2: 2.3265e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████▌                                                                                      | 2142/10000 [05:09<18:51,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2140, Loss: 1.1143e-04, Loss0: 9.8359e-05, Loss1: 1.3235e-03, Loss2: 2.3144e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████████▊                                                                                      | 2162/10000 [05:12<18:59,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2160, Loss: 1.0617e-04, Loss0: 9.3724e-05, Loss1: 1.3111e-03, Loss2: 2.3032e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████                                                                                      | 2182/10000 [05:15<18:40,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2180, Loss: 1.0134e-04, Loss0: 8.9450e-05, Loss1: 1.3053e-03, Loss2: 2.2923e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████▏                                                                                     | 2202/10000 [05:18<18:36,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2200, Loss: 9.6935e-05, Loss0: 8.5671e-05, Loss1: 1.2983e-03, Loss2: 2.2818e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████▍                                                                                     | 2222/10000 [05:20<18:33,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2220, Loss: 9.3083e-05, Loss0: 8.2140e-05, Loss1: 1.2887e-03, Loss2: 2.2717e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████▋                                                                                     | 2242/10000 [05:23<18:35,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2240, Loss: 8.9550e-05, Loss0: 7.8823e-05, Loss1: 1.2851e-03, Loss2: 2.2621e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████████▉                                                                                     | 2262/10000 [05:26<18:38,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2260, Loss: 8.5737e-05, Loss0: 7.5789e-05, Loss1: 1.2809e-03, Loss2: 2.2530e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████████                                                                                     | 2282/10000 [05:29<18:35,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2280, Loss: 8.2918e-05, Loss0: 7.3092e-05, Loss1: 1.2769e-03, Loss2: 2.2442e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████████▎                                                                                    | 2302/10000 [05:32<18:49,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2300, Loss: 7.9891e-05, Loss0: 7.0463e-05, Loss1: 1.2722e-03, Loss2: 2.2360e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████████▌                                                                                    | 2322/10000 [05:35<18:22,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2320, Loss: 7.6772e-05, Loss0: 6.7828e-05, Loss1: 1.2683e-03, Loss2: 2.2281e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████████▊                                                                                    | 2342/10000 [05:38<18:52,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2340, Loss: 7.4211e-05, Loss0: 6.5445e-05, Loss1: 1.2625e-03, Loss2: 2.2205e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████▉                                                                                    | 2362/10000 [05:41<18:28,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2360, Loss: 7.1561e-05, Loss0: 6.3173e-05, Loss1: 1.2557e-03, Loss2: 2.2128e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████▏                                                                                   | 2382/10000 [05:44<18:24,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2380, Loss: 6.9401e-05, Loss0: 6.1076e-05, Loss1: 1.2507e-03, Loss2: 2.2055e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████▍                                                                                   | 2402/10000 [05:47<20:28,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2400, Loss: 6.7252e-05, Loss0: 5.9028e-05, Loss1: 1.2459e-03, Loss2: 2.1986e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████▋                                                                                   | 2422/10000 [05:50<19:14,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2420, Loss: 6.4927e-05, Loss0: 5.7080e-05, Loss1: 1.2418e-03, Loss2: 2.1917e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████▊                                                                                   | 2442/10000 [05:53<17:55,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2440, Loss: 6.3286e-05, Loss0: 5.5189e-05, Loss1: 1.2387e-03, Loss2: 2.1852e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████                                                                                   | 2462/10000 [05:56<18:06,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2460, Loss: 6.0602e-05, Loss0: 5.3418e-05, Loss1: 1.2350e-03, Loss2: 2.1789e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████▎                                                                                  | 2482/10000 [05:59<18:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2480, Loss: 5.9127e-05, Loss0: 5.1723e-05, Loss1: 1.2320e-03, Loss2: 2.1726e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████▌                                                                                  | 2502/10000 [06:02<17:55,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2500, Loss: 5.7181e-05, Loss0: 5.0132e-05, Loss1: 1.2277e-03, Loss2: 2.1666e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████▋                                                                                  | 2522/10000 [06:05<17:50,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2520, Loss: 5.6388e-05, Loss0: 4.8687e-05, Loss1: 1.2251e-03, Loss2: 2.1608e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████▉                                                                                  | 2542/10000 [06:08<17:56,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2540, Loss: 5.3626e-05, Loss0: 4.7364e-05, Loss1: 1.2203e-03, Loss2: 2.1551e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████████▏                                                                                 | 2562/10000 [06:10<17:45,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2560, Loss: 5.2318e-05, Loss0: 4.6149e-05, Loss1: 1.2182e-03, Loss2: 2.1498e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████████▍                                                                                 | 2582/10000 [06:13<18:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2580, Loss: 5.0912e-05, Loss0: 4.5056e-05, Loss1: 1.2145e-03, Loss2: 2.1446e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████████▍                                                                                 | 2590/10000 [06:15<17:52,  6.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 64\u001b[0m\n\u001b[1;32m     56\u001b[0m r3_x1 \u001b[38;5;241m=\u001b[39m model_res[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m+\u001b[39m points[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m*\u001b[39m perm_vec \u001b[38;5;241m*\u001b[39m model_res[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpoints[:, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(model_res[:, \u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     57\u001b[0m                                                            x, one_vector, \n\u001b[1;32m     58\u001b[0m                                                            create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[1;32m     60\u001b[0m r3_x2 \u001b[38;5;241m=\u001b[39m model_res[:, \u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m points[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m*\u001b[39m perm_vec \u001b[38;5;241m*\u001b[39m model_res[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpoints[:, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(model_res[:, \u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     61\u001b[0m                                                            y, one_vector, \n\u001b[1;32m     62\u001b[0m                                                            create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[0;32m---> 64\u001b[0m r4_x1 \u001b[38;5;241m=\u001b[39m model_res[:, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m points[:, \u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m*\u001b[39m perm_vec \u001b[38;5;241m*\u001b[39m model_res[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpoints[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_res\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[1;32m     68\u001b[0m r4_x2 \u001b[38;5;241m=\u001b[39m model_res[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m points[:, \u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m*\u001b[39m perm_vec  \u001b[38;5;241m*\u001b[39m model_res[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpoints[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(model_res[:, \u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     69\u001b[0m                                                                          y, one_vector, \n\u001b[1;32m     70\u001b[0m                                                                          create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[1;32m     72\u001b[0m r5 \u001b[38;5;241m=\u001b[39m model_res[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m model_res[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m one_vector\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:502\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    498\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    499\u001b[0m         grad_outputs_\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    513\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    515\u001b[0m     ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# new version\n",
    "# Initialize model, optimizer, and loss functions\n",
    "model = pinn_model().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "max_dist = float('inf')\n",
    "\n",
    "# Training loop\n",
    "max_dist = float('inf')\n",
    "epochs = 10_000\n",
    "\n",
    "for cur_epoch in trange(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass: Get the model's predictions\n",
    "    model_res = model(points).requires_grad_(True)\n",
    "    \n",
    "    # Boundary condition calculations\n",
    "    press0 = model(pres0_x1_points)[:, 0].requires_grad_(True)\n",
    "    press1 = model(pres1_x1_points)[:, 0].requires_grad_(True)\n",
    "    soil0 = model(soil0_x1_points)[:, 1].requires_grad_(True)\n",
    "    swat0 = model(swat0_x1_points)[:, 2].requires_grad_(True)\n",
    "    \n",
    "    # Other boundary conditions (velocity, etc.)\n",
    "    uwat0_x2 = model(u0_x2_points)[:, 4].requires_grad_(True)\n",
    "    uwat1_x2 = model(u1_x2_points)[:, 4].requires_grad_(True)\n",
    "    uoil0_x2 = model(u0_x2_points)[:, 6].requires_grad_(True)\n",
    "    uoil1_x2 = model(u1_x2_points)[:, 6].requires_grad_(True)\n",
    "    \n",
    "    # Vector of ones and zeros\n",
    "    one_vector = torch.ones_like(model_res[:, 0])\n",
    "    \n",
    "    # Functions for r(t, x, y) for different conditions\n",
    "    r1 = 0.1 * torch.autograd.grad(model_res[:, 2], t, \n",
    "                                   one_vector, \n",
    "                                   create_graph=True)[0].to(DEVICE) +\\\n",
    "    torch.autograd.grad(model_res[:, 5], x, \n",
    "                        one_vector, \n",
    "                        create_graph=True)[0].to(DEVICE) +\\\n",
    "    torch.autograd.grad(model_res[:, 6], y, \n",
    "                        one_vector, \n",
    "                        create_graph=True)[0].to(DEVICE)\n",
    "    \n",
    "    \n",
    "    r2 = 0.1 * torch.autograd.grad(model_res[:, 1], t, \n",
    "                                   one_vector, \n",
    "                                   create_graph=True)[0].to(DEVICE) +\\\n",
    "    torch.autograd.grad(model_res[:, 3], x, \n",
    "                        one_vector, \n",
    "                        create_graph=True)[0].to(DEVICE) +\\\n",
    "    torch.autograd.grad(model_res[:, 4], y, \n",
    "                        one_vector, \n",
    "                        create_graph=True)[0].to(DEVICE)\n",
    "    \n",
    "    \n",
    "    \n",
    "    r3_x1 = model_res[:, 5] + points[:, 5] * perm_vec * model_res[:, 2]**points[:, 3] * (torch.autograd.grad(model_res[:, 0], \n",
    "                                                               x, one_vector, \n",
    "                                                               create_graph=True)[0].to(DEVICE))\n",
    "    \n",
    "    r3_x2 = model_res[:, 6] + points[:, 5] * perm_vec * model_res[:, 2]**points[:, 3] * (torch.autograd.grad(model_res[:, 0], \n",
    "                                                               y, one_vector, \n",
    "                                                               create_graph=True)[0].to(DEVICE))\n",
    "\n",
    "    r4_x1 = model_res[:, 3] + points[:, 6] * (1/3) * perm_vec * model_res[:, 2]**points[:, 4] * (torch.autograd.grad(model_res[:, 0], \n",
    "                                                                             x, one_vector, \n",
    "                                                                             create_graph=True)[0].to(DEVICE))\n",
    "    \n",
    "    r4_x2 = model_res[:, 4] + points[:, 6] * (1/3) * perm_vec  * model_res[:, 2]**points[:, 4] * (torch.autograd.grad(model_res[:, 0], \n",
    "                                                                             y, one_vector, \n",
    "                                                                             create_graph=True)[0].to(DEVICE))\n",
    "    \n",
    "    r5 = model_res[:, 2] + model_res[:, 1] - one_vector\n",
    "    \n",
    "    # Losses\n",
    "    loss0 = torch.mean(r1 ** 2 + r2 ** 2 + r3_x1 ** 2 + r3_x2 ** 2 + r4_x1 ** 2 + r4_x2 ** 2 + r5 ** 2).requires_grad_(True)\n",
    "    loss1 = torch.mean((press0 - one_vector) ** 2 + press1 ** 2 + (soil0 - one_vector) ** 2 + swat0 ** 2).requires_grad_(True)\n",
    "    loss2 = torch.mean((model_res[:, 0] - simulation_data[:, 0].to(DEVICE)) ** 2 + \n",
    "                       (model_res[:, 2] - simulation_data[:, 1].to(DEVICE)) ** 2 + \\\n",
    "                       (model_res[:, 1] - simulation_data[:, 2].to(DEVICE)) ** 2).requires_grad_(True)\n",
    "    \n",
    "    # Compute dynamic weights for the losses\n",
    "    w_ic, w_pde, w_data = compute_weights_grad_orthogonal_autograd(model, loss1, loss0, loss2)\n",
    "    \n",
    "    # Combine losses with weights\n",
    "    loss = w_ic * loss0 + w_pde * loss1 + w_data * loss2\n",
    "    dist = loss0 + loss1 + loss2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print and save model\n",
    "    if cur_epoch % 20 == 0:\n",
    "        text = f\"Epoch: {cur_epoch}, Loss: {float(loss.cpu().detach().numpy()):.4e}, \" + \\\n",
    "               f\"Loss0: {float(loss0.cpu().detach().numpy()):.4e}, Loss1: {float(loss1.cpu().detach().numpy()):.4e}, \" + \\\n",
    "               f\"Loss2: {float(loss2.cpu().detach().numpy()):.4e}\"\n",
    "        print(text)\n",
    "    if dist.cpu().detach().numpy() < max_dist:\n",
    "        torch.save(model.state_dict(), 'pinn_deep_model3_best.pth')\n",
    "        max_dist = dist.cpu().detach().numpy()\n",
    "    \n",
    "    if cur_epoch % 3000 == 0:\n",
    "        optimizer.param_groups[0]['lr'] /= 2  # Reduce learning rate after some epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e03fae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old version\n",
    "\n",
    "# # neural network returns:\n",
    "# # x - vector (pres\n",
    "# #             soil\n",
    "# #             swat\n",
    "# #             uoil_x,  \n",
    "# #             uoil_y,\n",
    "# #             uwat_x,  \n",
    "# #             uwat_y)\n",
    "\n",
    "# # change learning rate if necessary\n",
    "# # model input - t, x, y, pwat, poil, kwat, koil\n",
    "\n",
    "# model = pinn_model().to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# loss0_hist = []\n",
    "# loss1_hist = []\n",
    "# loss2_hist = []\n",
    "\n",
    "# w0_hist = []\n",
    "# w1_hist = []\n",
    "# w2_hist = []\n",
    "\n",
    "# # optimizer.param_groups[0]['lr'] = 0.0005\n",
    "# # perm_vec = torch.tensor(perm[list(x_list.astype(int)), list(y_list.astype(int)), -1])\n",
    "\n",
    "# max_dist = float('inf')\n",
    "# perm_vec = torch.tensor(perm[list(x_list.astype(int)), list(y_list.astype(int)), -1], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# epochs = 10_000\n",
    "# for cur_epoch in trange(epochs):\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     model_res = model(points).requires_grad_(True)\n",
    "#     # presseru bound\n",
    "#     press0 = model(pres0_x1_points)[:, 0].requires_grad_(True)\n",
    "#     press1 = model(pres1_x1_points)[:, 0].requires_grad_(True)\n",
    "    \n",
    "#     # struation boundary\n",
    "#     soil0 = model(soil0_x1_points)[:, 1].requires_grad_(True)\n",
    "#     swat0 = model(swat0_x1_points)[:, 2].requires_grad_(True)\n",
    "    \n",
    "#     # velocity boundary\n",
    "#     uwat0_x2 = model(u0_x2_points)[:, 4].requires_grad_(True)\n",
    "#     uwat1_x2 = model(u1_x2_points)[:, 4].requires_grad_(True)\n",
    "#     uoil0_x2 = model(u0_x2_points)[:, 6].requires_grad_(True)\n",
    "#     uoil1_x2 = model(u1_x2_points)[:, 6].requires_grad_(True)\n",
    "    \n",
    "#     one_vector = torch.ones_like(model_res[:, 0])\n",
    "#     zeros_vector = torch.zeros_like(model_res[:, 0])\n",
    "    \n",
    "#     # functions r(t,x)\n",
    "#     r1 = 0.1 * torch.autograd.grad(model_res[:, 2], t, \n",
    "#                                    one_vector, \n",
    "#                                    create_graph=True)[0].to(DEVICE) +\\\n",
    "#     torch.autograd.grad(model_res[:, 5], x, \n",
    "#                         one_vector, \n",
    "#                         create_graph=True)[0].to(DEVICE) +\\\n",
    "#     torch.autograd.grad(model_res[:, 6], y, \n",
    "#                         one_vector, \n",
    "#                         create_graph=True)[0].to(DEVICE)\n",
    "    \n",
    "    \n",
    "#     r2 = 0.1 * torch.autograd.grad(model_res[:, 1], t, \n",
    "#                                    one_vector, \n",
    "#                                    create_graph=True)[0].to(DEVICE) +\\\n",
    "#     torch.autograd.grad(model_res[:, 3], x, \n",
    "#                         one_vector, \n",
    "#                         create_graph=True)[0].to(DEVICE) +\\\n",
    "#     torch.autograd.grad(model_res[:, 4], y, \n",
    "#                         one_vector, \n",
    "#                         create_graph=True)[0].to(DEVICE)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     r3_x1 = model_res[:, 5] + points[:, 5] * perm_vec * model_res[:, 2]**points[:, 3] * (torch.autograd.grad(model_res[:, 0], \n",
    "#                                                                x, one_vector, \n",
    "#                                                                create_graph=True)[0].to(DEVICE))\n",
    "    \n",
    "#     r3_x2 = model_res[:, 6] + points[:, 5] * perm_vec * model_res[:, 2]**points[:, 3] * (torch.autograd.grad(model_res[:, 0], \n",
    "#                                                                y, one_vector, \n",
    "#                                                                create_graph=True)[0].to(DEVICE))\n",
    "\n",
    "#     r4_x1 = model_res[:, 3] + points[:, 6] * (1/3) * perm_vec * model_res[:, 2]**points[:, 4] * (torch.autograd.grad(model_res[:, 0], \n",
    "#                                                                              x, one_vector, \n",
    "#                                                                              create_graph=True)[0].to(DEVICE))\n",
    "    \n",
    "#     r4_x2 = model_res[:, 4] + points[:, 6] * (1/3) * perm_vec  * model_res[:, 2]**points[:, 4] * (torch.autograd.grad(model_res[:, 0], \n",
    "#                                                                              y, one_vector, \n",
    "#                                                                              create_graph=True)[0].to(DEVICE))\n",
    "    \n",
    "#     r5 = model_res[:, 2] + model_res[:, 1] - one_vector\n",
    "    \n",
    "    \n",
    "#     # Loss0\n",
    "#     loss0 = torch.mean(r1**2 + r2**2 + r3_x1**2 + r3_x2**2 + \n",
    "#                        r4_x1**2 + r4_x2**2 + r5**2).requires_grad_(True)\n",
    "    \n",
    "#     # Loss1\n",
    "#     loss1 = torch.mean((press0 - one_vector)**2 + press1**2 + \\\n",
    "#                        (soil0 - one_vector)**2 + swat0**2).requires_grad_(True) \n",
    "#     # +\\\n",
    "#     #                    uwat0_x2**2 + uwat1_x2**2 +\\\n",
    "#     #                    uoil0_x2**2 + uoil1_x2**2).requires_grad_(True)\n",
    "\n",
    "#     # x - vector (pres\n",
    "#     #             soil\n",
    "#     #             swat\n",
    "#     #             uoil_x,  \n",
    "#     #             uoil_y,\n",
    "#     #             uwat_x,  \n",
    "#     #             uwat_y)\n",
    "\n",
    "#     # Loss2\n",
    "#     loss2 = torch.mean((model_res[:,0] - simulation_data[:,0].to(DEVICE))**2 + \n",
    "#                        (model_res[:,2] - simulation_data[:,1].to(DEVICE))**2 + \\\n",
    "#                        (model_res[:,1] - simulation_data[:,2].to(DEVICE))**2).requires_grad_(True)\n",
    "    \n",
    "\n",
    "#     # algo for weights adjustment\n",
    "#     # l1 = loss1.clone().detach().requires_grad_(True)\n",
    "#     # l2 = loss2.clone().detach().requires_grad_(True)\n",
    "#     # l0 = loss0.clone().detach().requires_grad_(True)\n",
    "#     # l1.backward(retain_graph=True)\n",
    "#     # l2.backward(retain_graph=True)\n",
    "#     # l0.backward(retain_graph=True)\n",
    "#     # w0 = abs(l0 / (l0 + l1 + l2))\n",
    "#     # w1 = abs(l1 / (l1 + l0 + l2))\n",
    "#     # w2 = abs(l2 / (l1 + l0 + l2))\n",
    "\n",
    "#     w0, w1, w2 = compute_weights_grad_orthogonal_autograd(model, loss1, \n",
    "#                                                           loss0, loss2, kappa=10.0)\n",
    "    \n",
    "    \n",
    "#     # losses history\n",
    "#     loss0_hist.append(loss0.cpu().detach().numpy())\n",
    "#     loss1_hist.append(loss1.cpu().detach().numpy())\n",
    "#     loss2_hist.append(loss2.cpu().detach().numpy())\n",
    "    \n",
    "#     loss = w0*loss0 + w1*loss1 + w2*loss2\n",
    "#     dist = loss0 + loss1 + loss2\n",
    "#     loss.backward(retain_graph=True)\n",
    "#     optimizer.step()\n",
    "#     if cur_epoch % 3_000:\n",
    "#         optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / 2\n",
    "#     if dist.cpu().detach().numpy() < max_dist:\n",
    "#         torch.save(model.state_dict(), 'pinn_deep_model3_best_1k.pth')\n",
    "#         max_dist = dist.cpu().detach().numpy()\n",
    "#     if cur_epoch % 20 == 0:\n",
    "#         text = f'epoch: {cur_epoch}\\tloss: {float(dist.cpu().detach().numpy()), float(loss0.cpu().detach().numpy()), float(loss1.cpu().detach().numpy()), float(loss2.cpu().detach().numpy())}\\t' \n",
    "#         print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3f723e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(model):\n",
    "#     pwat = 2.0\n",
    "#     poil = 4.0\n",
    "#     vr = 0.3\n",
    "#     kwat = 1.0\n",
    "#     koil = 0.3\n",
    "\n",
    "#     # pwat = 1.0\n",
    "#     # poil = 1.0\n",
    "#     # vr = 1.0\n",
    "#     # kwat = 1.0\n",
    "#     # koil = 1.0\n",
    "#     pmin = 0.0\n",
    "#     pmax = 1.0\n",
    "#     nx0 = 50\n",
    "#     nx1 = 30\n",
    "#     nx2 = 1\n",
    "#     dx0 = 1.0 / nx0\n",
    "#     dx1 = 1.0 / nx1\n",
    "#     dx2 = 1.0 / nx2\n",
    "#     dt = 0.26e-1\n",
    "#     niter = 100\n",
    "\n",
    "#     poro = 0.1 + np.zeros((nx0, nx1, nx2))\n",
    "#     perm = np.ones((nx0, nx1, nx2))\n",
    "#     swat = np.zeros((nx0, nx1, nx2))\n",
    "#     soil = np.ones((nx0, nx1, nx2))\n",
    "\n",
    "\n",
    "#     pres, swat, soil = compute_solution(perm, poro,\n",
    "#                                         dx0, dx1, dx2, dt * niter, niter,\n",
    "#                                         pwat, kwat, poil, koil, vr,\n",
    "#                                         pmin=0.0, pmax=1.0)\n",
    "    \n",
    "#     time_for_model = (niter * dt) * torch.ones(1500)\n",
    "#     x_for_model = dx0 * torch.arange(50)\n",
    "#     y_for_model = dx1 * torch.arange(30)\n",
    "#     cartesian_points = torch.cartesian_prod(x_for_model, y_for_model)\n",
    "#     model_prediction = model(torch.stack((time_for_model, cartesian_points[:, 0], cartesian_points[:, 1]), -1))\n",
    "#     model_prediction = model_prediction.detach().numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.title('Water saturation, simulator')\n",
    "#     plt.imshow(swat[:, :, :, -1])\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel('x')\n",
    "#     plt.ylabel('y')\n",
    "#     plt.savefig('color_swat_sim.png', facecolor='b')\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.title('Water saturation, PINN')\n",
    "#     plt.imshow(model_prediction[:, 2].reshape(nx0, nx1, nx2))\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel('x')\n",
    "#     plt.ylabel('y')\n",
    "#     plt.savefig('color_swat_pinn.png')\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.title('Pressure, simulator')\n",
    "#     plt.imshow(pres[:, :, :, -1])\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel('x')\n",
    "#     plt.ylabel('y')\n",
    "#     plt.savefig('color_pressure_sim.png')\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.title('Pressure, PINN')\n",
    "#     plt.imshow(model_prediction[:, 0].reshape(nx0, nx1, nx2))\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel('x')\n",
    "#     plt.ylabel('y')\n",
    "#     plt.savefig('color_pressure_pinn.png')\n",
    "#     plt.show()    \n",
    "    \n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.title('Насыщенность воды')\n",
    "#     plt.scatter(np.linspace(0.0, 1.0, nx0), swat[:, 0, 0, -1], label='Модель')\n",
    "#     plt.scatter(np.linspace(0.0, 1.0, nx0), model_prediction[:, 2].reshape(nx0, nx1, nx2)[:, 0, 0], label='Симулятор')\n",
    "#     plt.grid()\n",
    "#     plt.xlabel('x')\n",
    "#     plt.ylabel('y')\n",
    "#     plt.legend()\n",
    "#     plt.savefig('swat_scatter.png')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.title('Pressure')\n",
    "#     plt.scatter(np.linspace(0.0, 1.0, nx0), pres[:, 0, 0, -1], label='Симулятор')\n",
    "#     plt.scatter(np.linspace(0.0, 1.0, nx0), model_prediction[:, 0].reshape(nx0, nx1, nx2)[:, 0, 0], label='Модель')\n",
    "#     plt.grid()\n",
    "#     plt.xlabel('x')\n",
    "#     plt.ylabel('y')\n",
    "#     plt.legend()\n",
    "#     plt.savefig('pres_scatter.png')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#     return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a699989",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# main(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0db4fa9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# x - vector (pres\n",
    "#             soil\n",
    "#             swat\n",
    "#             uoil_x,  \n",
    "#             uoil_y,\n",
    "#             uwat_x,  \n",
    "#             uwat_y)\n",
    "\n",
    "\n",
    "# 0 - pres, 1 - swat, 2 - soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deccdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_new(model):\n",
    "    perm = np.load('perm.npy')\n",
    "    nx0, nx1 = perm.shape\n",
    "    nx2 = 1\n",
    "    perm = np.reshape(perm, (nx0, nx1, nx2))\n",
    "    poro = 0.1 + np.zeros((nx0, nx1, nx2))\n",
    "\n",
    "    dx0 = 1.0 / nx0\n",
    "    dx1 = 1.0 / nx1\n",
    "    dx2 = 1.0 / nx2\n",
    "\n",
    "    pwat = 2.0\n",
    "    poil = 4.0\n",
    "    vr = 0.3\n",
    "    kwat = 1.0\n",
    "    koil = 0.3\n",
    "\n",
    "    pmin = 0.0\n",
    "    pmax = 1.0\n",
    "\n",
    "    dt = 0.26e-1\n",
    "    niter = 100\n",
    "\n",
    "\n",
    "    swat = np.zeros((nx0, nx1, nx2))\n",
    "    soil = np.ones((nx0, nx1, nx2))\n",
    "\n",
    "\n",
    "    pres, swat, soil = compute_solution(perm, poro,\n",
    "                                        dx0, dx1, dx2, dt * niter, niter,\n",
    "                                        pwat, kwat, poil, koil, vr,\n",
    "                                        pmin=0.0, pmax=1.0)\n",
    "    \n",
    "    time_for_model = (niter * dt) * torch.ones(64 * 64)\n",
    "    x_for_model = dx0 * torch.arange(64)\n",
    "    y_for_model = dx1 * torch.arange(64)\n",
    "    cartesian_points = torch.cartesian_prod(x_for_model, y_for_model)\n",
    "    model_prediction = model(torch.stack((time_for_model, cartesian_points[:, 0], cartesian_points[:, 1]), -1))\n",
    "    model_prediction = model_prediction.detach().numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Water saturation, simulator')\n",
    "    plt.imshow(swat[:, :, :, -1])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig('color_swat_sim.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Water saturation, PINN')\n",
    "    plt.imshow(model_prediction[:, 2].reshape(nx0, nx1, nx2))\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig('color_swat_pinn.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Pressure, simulator')\n",
    "    plt.imshow(pres[:, :, :, -1])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig('color_pressure_sim.png')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Pressure, PINN')\n",
    "    plt.imshow(model_prediction[:, 0].reshape(nx0, nx1, nx2))\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig('color_pressure_pinn.png')\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Water saturation at t = 0')\n",
    "    plt.scatter(np.linspace(0.0, 1.0, nx0), swat[:, 0, 0, -1], label='Simulator')\n",
    "    plt.scatter(np.linspace(0.0, 1.0, nx0), model_prediction[:, 2].reshape(nx0, nx1, nx2)[:, 0, 0], label='PINN')\n",
    "    plt.grid()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.savefig('swat_scatter.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Pressure at t = 0')\n",
    "    plt.scatter(np.linspace(0.0, 1.0, nx0), pres[:, 0, 0, -1], label='Simulator')\n",
    "    plt.scatter(np.linspace(0.0, 1.0, nx0), model_prediction[:, 0].reshape(nx0, nx1, nx2)[:, 0, 0], label='PINN')\n",
    "    plt.grid()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.savefig('pres_scatter.png')\n",
    "    plt.show()\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aef97b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_new(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89bc36-9ec2-4741-95ae-e23332f5f783",
   "metadata": {},
   "source": [
    "# Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4461f3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for pinn_model:\n\tMissing key(s) in state_dict: \"fc_out.weight\", \"fc_out.bias\". \n\tUnexpected key(s) in state_dict: \"fce.weight\", \"fce.bias\", \"fch.4.0.weight\", \"fch.4.0.bias\", \"fch.5.0.weight\", \"fch.5.0.bias\", \"fch.6.0.weight\", \"fch.6.0.bias\", \"fch.7.0.weight\", \"fch.7.0.bias\", \"fch.8.0.weight\", \"fch.8.0.bias\", \"fch.9.0.weight\", \"fch.9.0.bias\", \"fch.10.0.weight\", \"fch.10.0.bias\", \"fch.11.0.weight\", \"fch.11.0.bias\", \"fch.12.0.weight\", \"fch.12.0.bias\", \"fch.13.0.weight\", \"fch.13.0.bias\", \"fch.14.0.weight\", \"fch.14.0.bias\". \n\tsize mismatch for fcs.0.weight: copying a param with shape torch.Size([64, 3]) from checkpoint, the shape in current model is torch.Size([64, 7]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpinn_deep_model2_best_1k.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for pinn_model:\n\tMissing key(s) in state_dict: \"fc_out.weight\", \"fc_out.bias\". \n\tUnexpected key(s) in state_dict: \"fce.weight\", \"fce.bias\", \"fch.4.0.weight\", \"fch.4.0.bias\", \"fch.5.0.weight\", \"fch.5.0.bias\", \"fch.6.0.weight\", \"fch.6.0.bias\", \"fch.7.0.weight\", \"fch.7.0.bias\", \"fch.8.0.weight\", \"fch.8.0.bias\", \"fch.9.0.weight\", \"fch.9.0.bias\", \"fch.10.0.weight\", \"fch.10.0.bias\", \"fch.11.0.weight\", \"fch.11.0.bias\", \"fch.12.0.weight\", \"fch.12.0.bias\", \"fch.13.0.weight\", \"fch.13.0.bias\", \"fch.14.0.weight\", \"fch.14.0.bias\". \n\tsize mismatch for fcs.0.weight: copying a param with shape torch.Size([64, 3]) from checkpoint, the shape in current model is torch.Size([64, 7])."
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.load_state_dict(torch.load('pinn_deep_model2_best_1k.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fe6e654",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (4096x3 and 7x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m y_for_model \u001b[38;5;241m=\u001b[39m dx1 \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     68\u001b[0m cartesian_points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcartesian_prod(x_for_model, y_for_model)\n\u001b[0;32m---> 69\u001b[0m model_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_for_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcartesian_points\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcartesian_points\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m model_prediction \u001b[38;5;241m=\u001b[39m model_prediction\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     74\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[33], line 98\u001b[0m, in \u001b[0;36mpinn_model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mForward pass through the network\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    x: Output tensor of shape (batch_size, output_layer)\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Pass through the first layer\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Pass through hidden layers (no skip connections for simplicity)\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfch:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: linear(): input and weight.T shapes cannot be multiplied (4096x3 and 7x64)"
     ]
    }
   ],
   "source": [
    "def set_big_plot_style(scale: float = 1.2):\n",
    "    \"\"\"Global matplotlib style for bigger text/ticks/legend and sharper saved figs.\"\"\"\n",
    "    base = 18 * scale\n",
    "    title = 22 * scale\n",
    "    label = 20 * scale\n",
    "    ticks = 16 * scale\n",
    "    legend = 16 * scale\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        \"figure.dpi\": 150,\n",
    "        \"savefig.dpi\": 300,\n",
    "\n",
    "        \"font.size\": base,\n",
    "        \"axes.titlesize\": title,\n",
    "        \"axes.labelsize\": label,\n",
    "        \"xtick.labelsize\": ticks,\n",
    "        \"ytick.labelsize\": ticks,\n",
    "        \"legend.fontsize\": legend,\n",
    "\n",
    "        \"axes.titlepad\": 12,\n",
    "        \"axes.labelpad\": 10,\n",
    "    })\n",
    "\n",
    "def _add_colorbar_big(im):\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.ax.tick_params(labelsize=plt.rcParams.get(\"ytick.labelsize\", 16))\n",
    "    return cbar\n",
    "\n",
    "\n",
    "    # ---- make ALL plot text bigger ----\n",
    "set_big_plot_style(scale=1.3)  # try 1.0 .. 1.6\n",
    "\n",
    "perm = np.load('perm_3sigma.npy')\n",
    "nx0, nx1 = perm.shape\n",
    "nx2 = 1\n",
    "perm = np.reshape(perm, (nx0, nx1, nx2))\n",
    "poro = 0.1 + np.zeros((nx0, nx1, nx2))\n",
    "\n",
    "dx0 = 1.0 / nx0\n",
    "dx1 = 1.0 / nx1\n",
    "dx2 = 1.0 / nx2\n",
    "\n",
    "pwat = 2.0\n",
    "poil = 4.0\n",
    "vr = 0.3\n",
    "kwat = 1.0\n",
    "koil = 0.3\n",
    "\n",
    "pmin = 0.0\n",
    "pmax = 1.0\n",
    "\n",
    "dt = 0.15e-1\n",
    "niter = 100\n",
    "\n",
    "\n",
    "# swat = np.zeros((nx0, nx1, nx2))\n",
    "# soil = np.ones((nx0, nx1, nx2))\n",
    "\n",
    "\n",
    "# pres, swat, soil = compute_solution(perm, poro,\n",
    "#                                     dx0, dx1, dx2, dt * niter, niter,\n",
    "#                                     pwat, kwat, poil, koil, vr,\n",
    "#                                     pmin=0.0, pmax=1.0)\n",
    "\n",
    "time_for_model = (niter * dt) * torch.ones(64 * 64)\n",
    "x_for_model = dx0 * torch.arange(64)\n",
    "y_for_model = dx1 * torch.arange(64)\n",
    "cartesian_points = torch.cartesian_prod(x_for_model, y_for_model)\n",
    "model_prediction = model(torch.stack((time_for_model, cartesian_points[:, 0], cartesian_points[:, 1]), -1).to('mps'))\n",
    "model_prediction = model_prediction.cpu().detach().numpy()\n",
    "\n",
    "    \n",
    "    \n",
    "plt.figure()\n",
    "plt.title('Water saturation, sim')\n",
    "plt.imshow(swat[:, :, :, -1])\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('third_test/satur_sim_test2.png', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Water saturation, PINN')\n",
    "plt.imshow(model_prediction[:, 2].reshape(nx0, nx1, nx2))\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('third_test/satur_pinn_test2.png', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Pressure, sim')\n",
    "plt.imshow(pres[:, :, :, -1])\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('third_test/pres_sim_test2.png', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Pressure, PINN')\n",
    "plt.imshow(model_prediction[:, 0].reshape(nx0, nx1, nx2))\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('third_test/pres_pinn_test2.png', bbox_inches=\"tight\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f9231b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['MSE', 'MAE', 'R_2', 'RMSE']\n",
    "\n",
    "satur = [\n",
    "    np.mean((model_prediction[:, 2].reshape(nx0, nx1, nx2)[:, 0, 0] - swat[:, 0, 0, -1]) ** 2),\n",
    "    abs(np.mean(model_prediction[:, 2].reshape(nx0, nx1, nx2)[:, 0, 0] - swat[:, 0, 0, -1])),\n",
    "    r2_score(swat[:, 0, 0, -1], model_prediction[:, 2].reshape(nx0, nx1, nx2)[:, 0, 0]),\n",
    "    (np.mean((model_prediction[:, 2].reshape(nx0, nx1, nx2)[:, 0, 0] - swat[:, 0, 0, -1]) ** 2))**0.5\n",
    "]\n",
    "\n",
    "\n",
    "press = [\n",
    "    np.mean((model_prediction[:, 0].reshape(nx0, nx1, nx2)[:, 0, 0] - pres[:, 0, 0, -1]) ** 2),\n",
    "    abs(np.mean(model_prediction[:, 0].reshape(nx0, nx1, nx2)[:, 0, 0] - pres[:, 0, 0, -1])),\n",
    "    r2_score(pres[:, 0, 0, -1], model_prediction[:, 0].reshape(nx0, nx1, nx2)[:, 0, 0]),\n",
    "    (np.mean((model_prediction[:, 0].reshape(nx0, nx1, nx2)[:, 0, 0] - pres[:, 0, 0, -1]) ** 2))**0.5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4bf8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Metrics test': metrics,\n",
    "                     'Saturation test': satur,\n",
    "                     'Pressure test': press})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5b4e02bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics test</th>\n",
       "      <th>Saturation test</th>\n",
       "      <th>Pressure test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_2</td>\n",
       "      <td>0.979666</td>\n",
       "      <td>0.997936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>0.014821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metrics test  Saturation test  Pressure test\n",
       "0          MSE         0.000157       0.000220\n",
       "1          MAE         0.001920       0.004063\n",
       "2          R_2         0.979666       0.997936\n",
       "3         RMSE         0.012545       0.014821"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacbdf27",
   "metadata": {},
   "source": [
    "# Train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7463ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train results\n",
    "# pres, swat, soil\n",
    "metrics = ['MSE', 'MAE', 'R_2', 'RMSE']\n",
    "\n",
    "model_train_pred = model(points).cpu().detach().numpy()\n",
    "sim_data_train = simulation_data.detach().numpy()\n",
    "\n",
    "satur = [\n",
    "    np.mean((model_train_pred[:, 2] - sim_data_train[:, 1]) ** 2),\n",
    "    abs(np.mean(model_train_pred[:, 2] - sim_data_train[:, 1])),\n",
    "    r2_score(sim_data_train[:, 1], model_train_pred[:, 2]),\n",
    "    (np.mean((model_train_pred[:, 2] - sim_data_train[:, 1]) ** 2))**0.5\n",
    "]\n",
    "\n",
    "\n",
    "press = [\n",
    "    np.mean((model_train_pred[:, 0] - sim_data_train[:, 0]) ** 2),\n",
    "    abs(np.mean(model_train_pred[:, 0] - sim_data_train[:, 0])),\n",
    "    r2_score(sim_data_train[:, 0], model_train_pred[:, 0]),\n",
    "    (np.mean((model_train_pred[:, 0] - sim_data_train[:, 0]) ** 2))**0.5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7a98e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics train</th>\n",
       "      <th>Saturation train</th>\n",
       "      <th>Pressure train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>0.029610</td>\n",
       "      <td>0.102365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.086574</td>\n",
       "      <td>0.223145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_2</td>\n",
       "      <td>-0.575527</td>\n",
       "      <td>-0.342077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.172075</td>\n",
       "      <td>0.319945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metrics train  Saturation train  Pressure train\n",
       "0           MSE          0.029610        0.102365\n",
       "1           MAE          0.086574        0.223145\n",
       "2           R_2         -0.575527       -0.342077\n",
       "3          RMSE          0.172075        0.319945"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'Metrics train': metrics,\n",
    "                     'Saturation train': satur,\n",
    "                     'Pressure train': press})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3619129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20297553,  0.18941939,  0.17599034, ..., -0.00176622,\n",
       "       -0.00184536, -0.00193919], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prediction[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "652403c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.44713062e-35, -8.53961381e-34, -2.39543708e-36,  2.47118300e-35,\n",
       "        4.39105915e-35,  5.30774659e-03,  2.26973618e-09,  2.66007066e-01,\n",
       "       -5.36298139e-33,  3.18020087e-04,  3.65479797e-01, -3.66824767e-34,\n",
       "        1.91348440e-35,  3.99271786e-01,  3.20196867e-01,  1.07877780e-35,\n",
       "        2.08822027e-01, -8.84559499e-36,  3.29447573e-33, -2.84698854e-34,\n",
       "       -7.93899497e-35,  1.23250946e-01,  1.30221533e-05, -2.58770388e-35,\n",
       "        6.51038363e-06,  6.14137024e-35,  3.61193150e-01, -2.91501440e-33,\n",
       "        1.37437961e-09,  8.39369092e-03, -1.36051716e-34, -6.81980680e-34,\n",
       "       -2.80789922e-34, -1.08024698e-33, -5.01120295e-33,  1.43406942e-01,\n",
       "        1.44964123e-32, -1.35284706e-35,  1.90618164e-34,  3.88702117e-35,\n",
       "        2.66449305e-34,  2.46853814e-36, -4.73303984e-34, -4.11599347e-35,\n",
       "       -2.23551108e-34,  4.64662337e-33,  9.76494177e-34,  2.71849036e-01,\n",
       "        1.36786400e-34, -2.10284184e-34,  3.40055019e-01,  4.20269012e-01,\n",
       "        1.09593689e-32, -2.81258146e-34,  5.55555999e-01, -8.94739280e-34,\n",
       "        6.61621118e-34, -1.34836549e-34,  3.73219456e-36,  5.82216941e-02,\n",
       "        2.82173365e-01,  4.38447638e-34,  2.69026935e-01,  2.36161526e-07,\n",
       "       -5.98858536e-34,  1.37538481e-32, -1.18094864e-33, -1.71975764e-32,\n",
       "        3.57908070e-01,  6.27420110e-36,  2.10045412e-01, -4.66154040e-34,\n",
       "        2.95413485e-34,  1.28122374e-01,  1.18772939e-01,  7.46291976e-36,\n",
       "        3.91579503e-33,  8.13030668e-35, -6.65900101e-34, -1.73767452e-35,\n",
       "       -9.02684153e-35,  2.99565331e-33, -4.00237459e-36,  1.70651153e-02,\n",
       "       -1.38299849e-34,  2.83236972e-07,  5.09238846e-34,  3.43570879e-31,\n",
       "       -4.43749117e-37, -2.32089605e-34, -1.70829892e-33,  1.50535196e-01,\n",
       "        9.75836635e-35,  3.22955318e-34,  1.75764084e-01, -1.49246640e-34,\n",
       "       -2.39104367e-33,  6.92034095e-34, -1.72558897e-37,  5.81186154e-32,\n",
       "       -2.71283525e-34,  3.07607919e-01, -1.35837188e-34,  4.25708585e-34,\n",
       "        2.10760260e-34, -6.42866840e-36, -4.46324988e-35,  1.41932145e-01,\n",
       "       -8.32617342e-36, -8.19907310e-36,  1.47382845e-03, -3.44272908e-35,\n",
       "        1.37697120e-09, -2.12715694e-33,  1.84378471e-10,  5.39307371e-25,\n",
       "       -4.36157307e-35,  3.41017991e-01, -2.47257890e-35,  1.87790191e-12,\n",
       "        3.52724712e-34,  1.57639581e-28,  3.94096792e-01,  3.89547169e-01,\n",
       "        3.88326824e-01,  5.10489279e-34,  3.68835448e-11,  4.17819545e-02,\n",
       "        1.47498995e-01,  1.54908549e-29,  2.48271930e-32,  5.21018769e-34,\n",
       "       -1.31911037e-34,  5.31471853e-34,  2.43820190e-01, -4.10137326e-37,\n",
       "        7.61683605e-35,  3.32998869e-04,  6.43480301e-35, -3.61664347e-34,\n",
       "       -6.57285013e-36,  1.73766240e-01,  1.22652680e-01,  4.93055999e-01,\n",
       "        1.04531772e-01,  4.31958909e-34, -1.68589400e-34,  3.91005066e-28,\n",
       "       -1.38649559e-34,  2.81027734e-01,  3.48975718e-01, -6.27860920e-35,\n",
       "        1.53933336e-33, -1.34676388e-34,  2.37719387e-01,  5.99583378e-03,\n",
       "       -9.12035761e-35,  1.85848385e-01,  2.13299677e-01, -5.33956554e-34,\n",
       "        1.01410128e-01,  2.56348997e-01,  1.28469778e-34, -3.80566296e-37,\n",
       "        8.14599953e-34,  3.60313594e-01, -4.74927268e-37, -3.54778889e-35,\n",
       "        3.65479797e-01, -3.66901174e-33, -1.73143706e-34,  4.70197740e-37,\n",
       "       -9.70737929e-36,  2.31603131e-01,  2.20678255e-01,  3.19323040e-35,\n",
       "       -2.51602811e-33,  2.95002062e-34, -1.07586018e-34,  2.34583497e-01,\n",
       "        4.16810650e-07, -1.26737613e-33,  4.73250352e-35, -3.49125496e-35,\n",
       "       -7.01358704e-35, -8.97148603e-33,  2.45366797e-01,  3.92427325e-01,\n",
       "        3.11379050e-33,  1.02386773e-01,  1.41464099e-01,  2.01891155e-36,\n",
       "        1.37476415e-33,  3.16118091e-01,  1.69105425e-01, -2.56681497e-34,\n",
       "        2.00953037e-01,  1.23926492e-35,  1.81460306e-01,  2.71069944e-01,\n",
       "        3.24597311e-26,  1.75791875e-01,  1.57518354e-09, -1.91687496e-34,\n",
       "       -6.96654890e-35, -3.10345202e-35,  2.13045740e-23,  4.42472965e-01,\n",
       "        3.00931489e-29, -1.15587094e-34, -1.35284706e-35, -1.63026373e-36,\n",
       "        3.43955040e-01,  1.21933690e-05,  3.64555597e-01,  8.69498478e-36,\n",
       "       -8.96424645e-36,  2.67251432e-01, -1.36770825e-33,  2.05907236e-05,\n",
       "        5.45993616e-34, -1.69198306e-33,  2.94072658e-01, -3.42396819e-33,\n",
       "        1.34998473e-33,  2.01426536e-01,  3.61193150e-01, -1.13228318e-33,\n",
       "        5.87012491e-36,  2.66432256e-01,  3.46946181e-04,  1.45577386e-01,\n",
       "        4.07973887e-31,  2.74707824e-01,  3.96801233e-01,  4.42472965e-01,\n",
       "        4.46272403e-01,  2.77325697e-02,  4.63585585e-36, -4.10695686e-35,\n",
       "        7.61959255e-02,  3.85608763e-01,  4.48157221e-37,  3.19580180e-34,\n",
       "       -2.07019837e-33,  2.78130688e-35,  3.08385044e-01,  1.38291717e-01,\n",
       "        5.67041025e-10,  2.71891200e-34,  2.92220549e-37, -9.37926943e-35,\n",
       "        3.71216238e-01, -4.09409989e-34,  1.66180760e-01, -6.46661483e-35,\n",
       "        5.62567234e-01, -2.34738875e-35,  3.23756605e-01,  1.57639581e-28,\n",
       "        3.81856989e-33, -7.90367137e-34,  3.37931116e-34,  8.45953326e-32,\n",
       "        1.57639581e-28,  2.89166316e-18, -1.82671822e-35,  7.71094907e-35,\n",
       "       -1.68426300e-36, -3.01302712e-34,  3.60465343e-35,  3.78118068e-01,\n",
       "       -3.43529408e-33,  4.68221440e-34,  2.97447091e-34,  7.39116476e-31,\n",
       "        1.15670099e-14, -4.73818263e-34,  1.47776170e-35,  1.87943180e-35,\n",
       "       -5.06344192e-36,  1.32857545e-31,  1.03156976e-34,  2.70906061e-01,\n",
       "        3.18204851e-34,  3.59370664e-35,  3.35259527e-01, -2.65215035e-34,\n",
       "        1.05324294e-35, -2.62370339e-35,  2.52461791e-01, -2.72420816e-35,\n",
       "        2.50245541e-01,  1.30221533e-05,  3.48314911e-01,  3.45113307e-01,\n",
       "        3.00393403e-01,  4.46272403e-01,  2.42318064e-01, -1.86372278e-33,\n",
       "        4.63441024e-21, -2.08840677e-33,  2.09255397e-01, -1.03406769e-37,\n",
       "        2.10319449e-34, -2.23052992e-34,  3.42480279e-35,  2.18133931e-03,\n",
       "        2.42421318e-33,  1.12976968e-01,  3.35255325e-01, -1.17919863e-33,\n",
       "        4.63204173e-33,  1.67979474e-34,  5.81186154e-32,  2.46417299e-01,\n",
       "        2.39515498e-01,  3.41544161e-04,  3.00584167e-01,  1.28122374e-01,\n",
       "        2.05585513e-33, -3.21872945e-34,  3.08755517e-01,  4.12498683e-01,\n",
       "        3.73118825e-09, -1.77558422e-35,  1.93796208e-04,  8.49806009e-34,\n",
       "       -9.35693503e-36, -4.75276243e-36, -2.05267175e-33, -1.73062156e-35,\n",
       "       -1.71927804e-34,  3.45919793e-03, -1.68542380e-34,  1.00669459e-01,\n",
       "       -1.31398228e-35,  3.13394141e-35,  2.35683247e-01,  2.14726493e-01,\n",
       "        9.02343839e-02, -2.16962756e-33,  1.19150741e-07,  6.02308612e-34,\n",
       "        1.76234815e-33,  1.03611599e-33,  7.31790078e-06,  2.25765445e-33,\n",
       "        3.38824481e-01,  5.04066671e-36,  1.94693234e-06,  6.05987338e-03,\n",
       "        6.80317356e-37,  8.51640647e-10, -8.23360324e-35,  2.31972055e-34,\n",
       "        4.08695876e-34, -1.07322634e-35,  3.80860170e-35, -2.99927384e-35,\n",
       "        5.26422751e-04,  1.57581553e-01,  1.96724832e-01,  1.76239908e-01,\n",
       "       -2.23520251e-35, -1.95052129e-33,  2.09045663e-01,  2.57572979e-01,\n",
       "        9.05953496e-34,  1.12736562e-23, -4.20544859e-33,  2.62734008e-35,\n",
       "       -2.32089605e-34,  2.63809144e-33,  1.42175160e-33, -1.13452837e-34,\n",
       "       -3.76251644e-33,  5.09313822e-01,  2.90448457e-01,  6.20677834e-04,\n",
       "        3.60171469e-35,  2.39651965e-10,  5.78251993e-03,  2.21721744e-34,\n",
       "        2.10817565e-36, -1.70829892e-33,  1.10335757e-35,  3.46946181e-04,\n",
       "        9.85945887e-35,  5.04066671e-36, -4.65260664e-35,  7.50501715e-35,\n",
       "        2.29584850e-15,  6.05987338e-03,  3.97427293e-35,  4.22732025e-01,\n",
       "        1.90952986e-01,  4.50580716e-01, -1.68426300e-35, -1.73465350e-33,\n",
       "       -4.73818263e-34, -2.43938588e-34, -5.11707385e-36,  4.32848611e-34,\n",
       "        5.02729546e-34, -3.33448074e-34, -1.42507531e-33, -1.61365987e-34,\n",
       "        9.61848253e-35,  7.95931339e-32,  1.85228122e-23, -3.38380743e-33,\n",
       "        7.14243110e-19,  4.07063156e-01,  2.20966489e-34,  3.86343449e-01,\n",
       "        2.57714470e-32,  2.22802232e-03, -2.97765117e-35,  7.45175256e-35,\n",
       "       -5.61063454e-35,  5.21794793e-13, -3.44302295e-33, -8.21257291e-36,\n",
       "        3.37495893e-01, -7.43647114e-36, -4.97845735e-35,  1.54830828e-01,\n",
       "        1.59847028e-35, -2.26635311e-34, -1.13426741e-32,  2.89279014e-01,\n",
       "        4.39720660e-01,  3.58565083e-34, -1.07683276e-32, -4.14338249e-34,\n",
       "        1.17931471e-35,  5.41021275e-36,  9.08412412e-02, -4.77544580e-37,\n",
       "        1.47193933e-36,  4.85776544e-01,  3.45908165e-01,  2.73241282e-01,\n",
       "       -1.32956676e-35,  7.05957826e-36,  4.00942773e-01,  3.81109565e-01,\n",
       "        7.50413661e-14, -1.20770290e-34,  4.40189721e-33,  2.65349418e-01,\n",
       "        8.55651522e-34, -3.38380743e-33, -9.48220967e-34,  1.74773969e-35,\n",
       "       -9.48220967e-34, -3.03195350e-35,  3.24142567e-35,  2.65064746e-01,\n",
       "        5.74445307e-01,  3.36161997e-34,  2.35504494e-03, -1.23526824e-34,\n",
       "        7.39116476e-31,  3.75154495e-01,  4.98624414e-01, -4.33087384e-34,\n",
       "       -1.87799916e-35, -1.86327610e-33,  2.71370827e-05, -1.85434234e-36,\n",
       "        1.13876015e-36, -3.78473916e-34,  9.88982022e-02, -9.02684153e-35,\n",
       "        6.06696144e-34,  5.38038458e-33,  6.34822470e-07, -1.26163458e-33,\n",
       "        1.31945297e-01,  8.94195307e-03, -3.24592929e-34,  3.60784054e-01,\n",
       "        8.39369092e-03,  1.24426077e-35,  3.41017991e-01, -2.04822544e-35,\n",
       "        5.21743168e-34, -7.72111709e-34, -1.27864398e-35,  2.99133925e-35,\n",
       "        1.47700865e-34, -1.98752585e-34,  1.17090032e-01, -4.87501017e-34,\n",
       "       -9.48220967e-34,  1.53889108e-34,  3.92526895e-01,  1.84662816e-35,\n",
       "       -1.43148264e-32,  1.82404995e-01,  2.83236972e-07, -2.50568376e-34,\n",
       "       -8.19907310e-36,  2.62369335e-01, -2.17407680e-35, -5.36010730e-35,\n",
       "        4.77015608e-35,  1.87050539e-35,  1.01410128e-01,  3.72516841e-01,\n",
       "       -6.25069121e-34,  3.21154416e-01,  4.45956843e-34,  3.41362655e-01,\n",
       "        3.41108739e-01,  1.57049719e-35,  1.96818897e-34,  1.62453319e-34,\n",
       "        1.15968939e-02,  3.74043680e-36,  7.47200633e-33, -1.73143706e-34,\n",
       "        7.50945464e-34, -3.67294965e-34,  3.52538103e-36,  8.35467916e-35,\n",
       "        1.94954008e-01,  1.94437825e-06,  8.78784880e-02,  3.65787393e-34,\n",
       "        1.07909206e-33,  1.57351674e-34, -6.08457035e-33,  8.92755633e-34,\n",
       "       -3.98786459e-36,  1.97110683e-01, -5.00422051e-33,  3.55189741e-01,\n",
       "       -2.36445987e-33, -3.05072522e-33, -4.96863830e-33,  1.18143060e-34,\n",
       "        2.70584106e-36, -7.22047405e-36,  6.34822470e-07,  3.48975718e-01,\n",
       "        3.27146315e-29,  1.71624784e-10, -2.19523570e-35,  9.25283879e-02,\n",
       "        4.49086696e-01,  3.89046311e-01, -1.83970743e-34,  1.17931471e-35,\n",
       "        4.53624942e-08, -4.96646363e-37,  1.95619892e-34, -4.77344746e-34,\n",
       "        4.38094990e-33,  7.43232295e-06, -9.35693503e-36, -5.81999008e-34,\n",
       "        1.29793972e-33, -1.34420130e-33,  6.07424453e-02,  4.38753266e-36,\n",
       "       -4.23593063e-34, -5.17217514e-37, -2.32089605e-34,  9.74161556e-35,\n",
       "        2.31434107e-02, -5.05932769e-35,  2.08955141e-35,  3.50401402e-01,\n",
       "       -5.26224740e-35, -6.23024496e-34,  4.45652008e-01,  5.16951494e-02,\n",
       "       -5.98858536e-34,  2.97051831e-34, -2.84146372e-34,  9.99170198e-35,\n",
       "        2.88719088e-01,  1.40793367e-34,  2.18815073e-01,  2.62734008e-35,\n",
       "        8.48038347e-22, -4.87501017e-34,  1.28330922e-36,  3.80817111e-09,\n",
       "        2.99915337e-06, -2.69540855e-35,  2.62909115e-34,  1.45556655e-07,\n",
       "       -2.04822544e-35,  1.39384243e-34,  4.31994174e-37,  1.26031802e-33,\n",
       "       -1.09636889e-35,  4.78202857e-34,  3.16824968e-33,  3.36132610e-35,\n",
       "        2.10887360e-35, -1.04129992e-33, -1.53457114e-37, -7.82438427e-36,\n",
       "        6.20677834e-04,  1.94954008e-01,  3.85529906e-01,  1.74773969e-35,\n",
       "       -2.17839087e-33,  2.54898603e-36, -4.33992514e-35,  1.36653569e-33,\n",
       "       -1.09062366e-34,  1.85512845e-34,  9.14701330e-21,  1.54837286e-25,\n",
       "        3.73450249e-01,  1.88191003e-30,  5.94884515e-01,  1.23476865e-33,\n",
       "        1.79248195e-35,  1.18977041e-05,  5.91611613e-34,  1.90853263e-34,\n",
       "        9.20062540e-16, -2.23343927e-36,  8.87398800e-28,  1.44938453e-35,\n",
       "        3.20510290e-34,  1.28110517e-35, -4.24338767e-35, -1.67294887e-35,\n",
       "        2.95761726e-35,  1.18584105e-32,  1.62335770e-35,  3.54879908e-36,\n",
       "        3.60665888e-01,  5.26489226e-34,  1.42633498e-01,  9.08412412e-02,\n",
       "        2.65774488e-01, -9.44068901e-36,  4.60201055e-01,  2.25268799e-35,\n",
       "        2.57696092e-01, -3.59513927e-35,  3.00584167e-01,  3.54543626e-01,\n",
       "        1.84321188e-35,  6.11626183e-06, -1.79593496e-34, -2.08191804e-34,\n",
       "        9.61330688e-22,  8.96189511e-02,  2.46474579e-01,  2.49093291e-34,\n",
       "       -2.64750715e-35, -4.94633329e-35,  2.57714470e-32, -6.41817565e-33,\n",
       "        2.71069944e-01, -2.06813537e-36,  3.50025483e-35, -7.20845462e-34,\n",
       "        2.65711545e-23,  1.69396964e-33,  2.97447091e-34, -7.63260237e-34,\n",
       "       -5.49977073e-35,  9.74842975e-36,  5.76625449e-11,  1.88697994e-33,\n",
       "       -1.59277721e-33, -3.33448074e-34,  1.28200561e-01,  8.09621734e-36,\n",
       "       -2.15068446e-34,  1.62952904e-36, -1.10825607e-34,  1.99228083e-07,\n",
       "        1.51485622e-01,  3.26930931e-05,  1.23963226e-35,  6.91704957e-37,\n",
       "        1.82895166e-34,  2.15088248e-01,  1.19782874e-35,  3.60046685e-01,\n",
       "        3.49592020e-35,  7.59029927e-34, -4.74927268e-37,  3.06984782e-01,\n",
       "        6.32571714e-34,  5.02518535e-01, -2.37405190e-33, -9.70737929e-36,\n",
       "        4.56674576e-01,  5.27411254e-37,  1.09365635e-01,  5.10550380e-01,\n",
       "       -2.17839087e-33, -8.63431825e-35,  3.99918616e-01,  1.08481236e-01,\n",
       "        1.43239144e-02,  4.75614592e-02,  2.48263523e-01,  7.95931339e-32,\n",
       "        2.31434107e-02,  1.47860439e-04,  6.75203955e-35,  3.89707234e-34,\n",
       "        3.04570586e-35,  1.56317239e-34, -1.07119274e-33, -2.71339361e-34,\n",
       "        6.76276594e-37, -1.68426300e-35, -3.43633733e-34, -1.23944124e-34,\n",
       "        3.05486977e-01, -3.73416903e-36, -8.08887050e-36,  2.51635551e-01,\n",
       "       -1.13135454e-33,  2.92256624e-01,  1.02793399e-34,  2.22303499e-13,\n",
       "        6.58093165e-37,  1.27781966e-33,  4.77015608e-35,  5.67847371e-01,\n",
       "        3.24053705e-01,  5.17954171e-01,  1.69277064e-33,  5.61604181e-34,\n",
       "        4.93823029e-02, -2.21801090e-36,  6.61009861e-35,  4.36351001e-01,\n",
       "        1.87919862e-12,  1.13049643e-33, -2.83999435e-35, -4.51466238e-34,\n",
       "       -1.54119064e-34,  4.63585585e-36, -1.43837897e-34,  1.25428186e-34,\n",
       "        2.17390342e-33,  1.26963455e-33,  5.31276427e-34,  3.28621201e-34,\n",
       "        4.76595368e-34,  3.71566623e-01,  3.30796833e-16, -6.50636123e-36,\n",
       "       -6.08457035e-33,  2.35109776e-01,  3.97427293e-35, -5.26960012e-33,\n",
       "       -9.14505218e-35, -3.48441597e-34,  2.94072658e-01,  1.47427195e-35,\n",
       "        1.37967303e-01, -7.53051068e-37,  4.28943723e-01,  9.01812817e-34,\n",
       "       -2.10789647e-34, -1.53457114e-37, -7.67444997e-34, -1.97394654e-32,\n",
       "       -1.94916249e-36,  1.83076695e-01, -2.72420816e-35,  1.84064895e-01,\n",
       "        3.83833023e-27,  4.26104844e-01,  2.23180816e-01, -1.06720193e-34,\n",
       "       -2.58211910e-32,  1.63393199e-01,  5.45993616e-34,  1.44491766e-34,\n",
       "        2.33429668e-34,  2.99796977e-37,  2.25268799e-35,  1.48779969e-33,\n",
       "        1.52462995e-35,  3.30016613e-01,  2.50190272e-17, -2.08840677e-33,\n",
       "        2.68693522e-11,  5.38023764e-35, -1.91664354e-35, -4.16407119e-34,\n",
       "        1.09900089e-34,  1.21167150e-12,  3.61027376e-35,  2.16856308e-04,\n",
       "        9.64513791e-15,  1.84064895e-01, -1.76248921e-33,  1.49866126e-33,\n",
       "        2.56959601e-13, -3.88492654e-33, -4.87501017e-34,  3.89874621e-09,\n",
       "       -3.44258214e-35, -1.04924626e-34,  3.19580180e-34,  2.52124143e-33,\n",
       "        1.35764190e-32, -1.73465350e-33, -8.25490908e-35,  2.23342457e-34,\n",
       "       -3.54731281e-33, -1.39321795e-35,  6.64765565e-34,  2.05876081e-34,\n",
       "       -3.52648305e-35,  5.47672927e-01,  4.86676246e-01,  2.06919819e-01,\n",
       "        1.12207989e-33,  5.16951494e-02,  2.79029209e-08,  5.11475224e-34,\n",
       "       -3.25247532e-34,  2.96912789e-01,  3.40800498e-33,  3.33476037e-01,\n",
       "        3.89433414e-01,  2.04394539e-23,  6.57301176e-34,  4.29281861e-01,\n",
       "        2.40501352e-02,  1.44938453e-35,  1.93257149e-34,  3.86343449e-01,\n",
       "        1.62825406e-01, -3.10918256e-36,  4.39047140e-33, -1.13205616e-35,\n",
       "        1.03502865e-33,  1.52990590e-35, -2.23052992e-34,  2.70374358e-01,\n",
       "        5.26285351e-35,  1.86015949e-01,  1.72547728e-01, -8.94739280e-34,\n",
       "        1.48541609e-23,  1.31802304e-36, -1.24582197e-35,  3.19945157e-01,\n",
       "       -2.16220431e-34,  3.26930931e-05,  2.89405793e-01,  5.87747175e-36,\n",
       "        6.82924106e-35,  8.57520440e-24,  1.62035003e-01,  4.04365355e-33,\n",
       "       -4.42550113e-34,  5.70499000e-34, -2.06813537e-36,  4.39105915e-35,\n",
       "       -4.11599347e-35,  1.05493255e-01,  1.04764335e-01,  3.65359991e-34,\n",
       "       -8.16015689e-34,  1.51655808e-01, -2.70833898e-35, -8.80368862e-34,\n",
       "       -3.79831612e-37,  1.42633498e-01,  1.07205085e-35,  1.50535196e-01,\n",
       "        1.77932229e-33,  5.11709869e-01,  1.48824185e-01, -5.28137857e-34,\n",
       "       -1.31138150e-33,  3.79414409e-01,  7.95931339e-32,  4.16810650e-07,\n",
       "       -3.59630466e-34, -2.47855923e-34,  3.23756605e-01,  2.67251432e-01,\n",
       "        2.56984115e-01,  4.06133298e-35,  1.70427456e-01,  2.86415076e-34,\n",
       "        1.87983898e-29, -1.23338745e-35,  1.13722025e-33,  1.25293255e-01,\n",
       "        2.91369785e-34,  1.25428186e-34,  2.13117704e-01, -2.11919591e-36,\n",
       "       -1.22986096e-36, -2.84146372e-34,  8.08593177e-36,  1.91348440e-35,\n",
       "        2.58993894e-01,  4.92818602e-26,  2.12003492e-33,  6.18541013e-33,\n",
       "        6.20091637e-36,  2.02799224e-34, -2.37987060e-33,  8.01011238e-35,\n",
       "       -2.36233039e-36,  1.17756784e-01,  1.79523155e-01,  1.37861977e-34,\n",
       "        3.48748603e-34,  1.25445854e-02,  3.46727340e-33,  3.93790608e-35,\n",
       "        5.38194537e-01,  4.42790866e-01,  1.43239144e-02, -4.51392769e-34,\n",
       "        2.18216567e-34,  5.94541177e-07, -2.34819727e-33,  1.64818708e-33,\n",
       "       -1.12197997e-34,  3.79919774e-35, -9.55529970e-35,  3.52278025e-34,\n",
       "        2.82386571e-01,  5.88137380e-16,  2.29166731e-01,  2.46064186e-01,\n",
       "       -4.46324988e-35,  4.40189721e-33,  5.85002899e-01, -4.39130600e-33,\n",
       "        1.53328544e-36,  2.82177419e-35,  1.36254189e-27,  2.52363943e-37,\n",
       "        1.57457468e-35,  1.60760254e-01,  4.07678634e-01,  4.00599659e-34,\n",
       "        3.70383576e-34, -4.36077254e-33, -3.45768679e-35,  1.93904713e-01,\n",
       "        3.61214936e-01, -3.54693665e-34,  1.76911900e-33,  1.90929670e-35,\n",
       "        6.25656868e-35,  4.98594745e-34,  4.75697182e-02,  3.52750599e-01,\n",
       "       -1.23621231e-34,  2.70400435e-36,  4.31114823e-01,  7.97190881e-34,\n",
       "        1.57457468e-35, -7.03680306e-36,  3.33807319e-01,  1.81529328e-01,\n",
       "        6.83160876e-33,  6.32571714e-34,  2.58207470e-01,  4.08610065e-33,\n",
       "       -9.09879647e-34,  2.21676126e-01,  6.25520333e-05,  2.90137768e-01,\n",
       "        3.67989480e-01, -3.78391632e-34, -2.65215035e-34,  4.37654912e-01,\n",
       "       -1.09355064e-33,  5.82216941e-02,  1.67140603e-35,  1.71864161e-03,\n",
       "        9.76872540e-36,  3.68840144e-26,  4.21580523e-02,  1.88697994e-33,\n",
       "        1.17669508e-01,  3.16731006e-01,  5.77679066e-34,  1.33521465e-35],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a5293d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.70193762e-01,  1.66147351e-01,  8.31827521e-02,  6.08858690e-02,\n",
       "       -1.91152096e-04,  2.36591399e-01,  1.94048792e-01,  2.43403807e-01,\n",
       "        1.64687976e-01,  1.91318005e-01,  2.43978798e-01,  1.03926934e-01,\n",
       "        5.91024756e-03,  2.40260988e-01,  2.43010476e-01,  1.46131217e-03,\n",
       "        2.37345070e-01,  2.39244878e-01,  2.04917714e-01,  2.29561985e-01,\n",
       "        1.26147270e-03,  2.36038059e-01,  2.41473317e-01,  7.94987679e-02,\n",
       "        2.35620886e-01,  2.18681082e-01,  2.37730891e-01,  2.08301157e-01,\n",
       "        2.19997048e-01,  2.38798305e-01,  2.38406524e-01,  1.59989446e-01,\n",
       "        2.39027470e-01,  1.90100163e-01,  2.42234007e-01,  2.35784337e-01,\n",
       "        2.35847861e-01,  1.51500493e-01,  2.37624228e-01,  1.27802640e-02,\n",
       "        1.82718813e-01,  1.70300901e-03,  2.28362143e-01,  1.27330288e-01,\n",
       "       -2.06232071e-05,  2.10888177e-01,  5.47388196e-03,  2.46441618e-01,\n",
       "        4.06682491e-04,  2.17749342e-01,  2.40237534e-01,  2.42527708e-01,\n",
       "        2.02617109e-01,  2.31583506e-01,  4.21917230e-01,  2.35443085e-01,\n",
       "        8.35916400e-03,  1.48782134e-03,  1.54696405e-03,  2.40810812e-01,\n",
       "        2.43552998e-01,  2.32916012e-01,  2.44797230e-01,  2.45690018e-01,\n",
       "       -2.04861164e-03,  1.94059953e-01,  1.69348612e-01,  2.14577213e-01,\n",
       "        2.37334967e-01,  1.79244146e-01,  2.22536027e-02,  4.82989848e-03,\n",
       "        1.87812477e-01,  2.40942866e-01,  2.59982347e-01,  6.69098571e-02,\n",
       "        1.25472248e-03,  1.37425959e-03,  2.40765512e-01,  2.31412798e-01,\n",
       "        1.99512213e-01,  2.59020329e-01,  1.84979931e-01,  2.38707632e-01,\n",
       "        8.02494586e-03,  2.39792317e-01,  2.08559871e-01, -7.36673176e-03,\n",
       "        2.35761002e-01,  2.07222998e-03,  2.24903822e-01, -8.39722157e-03,\n",
       "        1.47325784e-01,  1.27691254e-01,  2.07488135e-01, -2.78025866e-04,\n",
       "        2.01154605e-01,  4.78651226e-02,  2.14099482e-01,  2.37999469e-01,\n",
       "        2.37997070e-01,  2.41791815e-01,  9.17788595e-02,  7.08922744e-04,\n",
       "        2.40929365e-01,  2.33342394e-01,  7.92571902e-03,  2.36736700e-01,\n",
       "        2.34147370e-01,  2.19993174e-01,  2.36488014e-01,  1.89264715e-01,\n",
       "        2.45173290e-01,  7.86194429e-02,  3.19713354e-03,  4.76291776e-03,\n",
       "        2.29088962e-03,  2.57752419e-01,  1.13335937e-01,  2.27628112e-01,\n",
       "        2.31388211e-03,  2.06047356e-01,  2.50273615e-01,  2.31615052e-01,\n",
       "        2.39995152e-01,  2.44244173e-01,  2.47905940e-01, -5.67170978e-03,\n",
       "        2.44723499e-01,  2.40152836e-01,  2.54777670e-01,  5.24628162e-03,\n",
       "        2.35552177e-01,  1.79837555e-01,  2.43956372e-01,  1.46145374e-01,\n",
       "        2.24756092e-01,  1.99061066e-01,  2.38080740e-01,  2.52794236e-01,\n",
       "        2.29475930e-01,  2.42225274e-01,  2.37648547e-01,  2.35253096e-01,\n",
       "        2.64374822e-01,  2.13884443e-01,  2.01304913e-01, -5.70747256e-03,\n",
       "        2.33609930e-01,  2.40272760e-01,  2.46237174e-01,  2.14646518e-01,\n",
       "        1.39579743e-01,  1.71295226e-01,  2.37295777e-01, -6.32604957e-03,\n",
       "        2.33597964e-01,  2.41445124e-01,  2.35855818e-01,  3.74181569e-03,\n",
       "       -1.88801885e-02,  4.12803888e-02,  2.85539776e-02,  1.30149111e-01,\n",
       "        1.81219295e-01,  2.38203824e-01,  1.52627677e-01,  2.17179656e-01,\n",
       "        2.43978798e-01,  3.13042551e-02,  1.58950076e-01,  8.37489963e-04,\n",
       "        7.54594803e-04,  2.36709297e-01,  2.41053775e-01,  6.40213490e-03,\n",
       "        9.29932296e-03,  1.77654624e-03,  4.87633049e-03,  2.48590663e-01,\n",
       "        8.81632566e-02,  2.02283129e-01,  1.02039456e-01,  2.29549095e-01,\n",
       "        2.13208824e-01,  2.37036407e-01,  2.51545429e-01, -1.76483840e-02,\n",
       "        2.42005914e-01,  2.41653845e-01,  2.40323588e-01,  1.35070086e-03,\n",
       "        2.28964746e-01,  2.29689986e-01,  2.40700051e-01,  2.41835669e-01,\n",
       "        1.58251852e-01,  2.31599331e-01,  2.38724276e-01,  2.42240697e-01,\n",
       "        2.13248417e-01,  2.42869511e-01,  1.71964154e-01,  2.38193959e-01,\n",
       "        2.42579684e-01,  2.37796471e-01,  2.49669790e-01,  2.37886161e-01,\n",
       "       -2.18324363e-03,  2.35713258e-01,  1.51500493e-01,  1.93986163e-01,\n",
       "        2.46853754e-01,  4.22003388e-01,  2.37695023e-01,  7.66634941e-03,\n",
       "        1.65238976e-03,  2.37209618e-01,  2.04654604e-01,  2.42369026e-01,\n",
       "        1.03719532e-03,  9.26598534e-02,  2.41787568e-01,  2.26135015e-01,\n",
       "        9.95049328e-02,  2.02202052e-02,  2.37730891e-01,  2.34872892e-01,\n",
       "        9.35816318e-02,  2.41563320e-01,  2.41190702e-01,  2.41906330e-01,\n",
       "        6.57236055e-02,  2.41971031e-01,  2.38298565e-01,  2.37886161e-01,\n",
       "        2.45856300e-01,  1.04495734e-02,  2.41202474e-01,  1.81926474e-01,\n",
       "        1.88504219e-01,  2.42292583e-01,  2.32994229e-01,  1.64054126e-01,\n",
       "        2.34334856e-01,  2.32480869e-01,  4.11155075e-01,  2.44344175e-01,\n",
       "        2.37900048e-01,  2.36551240e-01,  1.72167674e-01,  3.55073959e-02,\n",
       "        2.36633018e-01,  1.52734250e-01,  2.39281818e-01,  2.40381390e-01,\n",
       "        2.12243050e-01,  1.82054192e-01, -2.86831558e-02,  2.06047356e-01,\n",
       "        1.67950019e-01,  2.18363136e-01,  1.48970768e-01,  2.35501498e-01,\n",
       "        2.06047356e-01, -9.14971530e-03,  1.23438239e-03,  6.87301159e-03,\n",
       "        2.08062351e-01,  6.14316761e-03,  8.45864415e-04,  1.60851330e-01,\n",
       "        1.86000094e-01,  2.49280721e-01,  1.87259912e-03,  2.37244785e-01,\n",
       "        1.11113951e-01,  1.00547157e-01,  2.27420926e-01,  2.34829277e-01,\n",
       "        2.33062387e-01,  1.75727338e-01,  1.50406435e-01,  2.35926986e-01,\n",
       "        8.17628950e-02,  1.50606036e-04,  1.82609126e-01,  2.24953890e-03,\n",
       "       -3.22580338e-04,  6.52523637e-02,  2.36358106e-01,  1.53120607e-01,\n",
       "        2.35949099e-01,  2.41473317e-01,  7.68124908e-02,  1.15227796e-01,\n",
       "        2.57882625e-01,  2.45856300e-01,  2.49134600e-01,  2.11120486e-01,\n",
       "        5.07469699e-02,  1.68579787e-01,  2.35927641e-01,  2.27902830e-02,\n",
       "        1.28896773e-01,  1.98780447e-02,  2.33697176e-01,  2.42639646e-01,\n",
       "        4.51378524e-03,  5.20110130e-04,  2.43867368e-01,  2.41922677e-01,\n",
       "        2.59389043e-01,  2.55275369e-01,  2.37999469e-01,  1.50025368e-01,\n",
       "        2.41800219e-01,  1.97576135e-01,  2.48037234e-01,  2.40942866e-01,\n",
       "        2.41592288e-01,  2.35227540e-01,  2.38849670e-01,  2.50748843e-01,\n",
       "        1.63089111e-01,  1.67423487e-03,  9.93295014e-03,  2.36041605e-01,\n",
       "        4.64971960e-02,  7.65706301e-02,  2.36572504e-01,  2.29183793e-01,\n",
       "        2.29408056e-01,  2.43966445e-01,  2.35637456e-01,  2.28440776e-01,\n",
       "        2.20140338e-01,  2.35509112e-01,  2.35838473e-01,  2.38038793e-01,\n",
       "        1.75730646e-01,  9.39816236e-05,  2.40856797e-01,  8.48463550e-02,\n",
       "        1.31644279e-01,  1.70293093e-01,  2.41609246e-01,  1.81488693e-01,\n",
       "        2.40413085e-01,  1.56383812e-01,  2.49274746e-01,  3.58272672e-01,\n",
       "       -7.45356083e-05,  2.42922574e-01,  9.24289227e-04,  2.27770686e-01,\n",
       "        7.87369609e-02,  2.37233758e-01,  2.33843088e-01,  6.82801008e-04,\n",
       "       -1.00994259e-02,  2.39730611e-01,  2.44008079e-01,  2.43140072e-01,\n",
       "        1.05774403e-03,  2.38448799e-01,  3.53658199e-03, -1.57591403e-02,\n",
       "        4.10253406e-02,  3.81684303e-03,  2.37894267e-01,  2.68396735e-03,\n",
       "        2.07222998e-03,  2.42710456e-01,  1.56865597e-01,  1.50827259e-01,\n",
       "        2.39266053e-01,  5.06168455e-02,  5.81505671e-02,  2.20777065e-01,\n",
       "        1.86162248e-01,  1.49606571e-01,  3.21571946e-01,  2.37201720e-01,\n",
       "        1.61610544e-03,  2.24903822e-01,  8.32398236e-03,  2.41190702e-01,\n",
       "        1.10945106e-03,  1.56383812e-01,  1.96708739e-03,  2.22177997e-01,\n",
       "        2.36158073e-01,  3.58272672e-01,  2.20220059e-01,  2.43958071e-01,\n",
       "        2.37583250e-01,  4.15965140e-01,  5.62737882e-03,  1.91604584e-01,\n",
       "        1.00547157e-01,  2.39510119e-01, -2.92956829e-05,  1.87022462e-01,\n",
       "        1.82781085e-01,  9.17169973e-02,  5.76293468e-03,  2.48861372e-01,\n",
       "        5.21799251e-02,  1.97791532e-01,  2.05332696e-01,  1.79383829e-01,\n",
       "        1.74106181e-01,  5.39674878e-01,  1.99193209e-02,  5.79512179e-01,\n",
       "        2.40033746e-01,  2.35615671e-01,  1.62914142e-01,  9.01514143e-02,\n",
       "        7.77325034e-03,  2.36181796e-01,  1.36771321e-01,  2.33359575e-01,\n",
       "        2.37347722e-01,  3.09690833e-04,  1.92917868e-01,  2.35096425e-01,\n",
       "        1.63486794e-01,  1.72520429e-01,  1.19570963e-01,  3.12042832e-02,\n",
       "        2.48848110e-01,  2.36503243e-01,  1.82621345e-01,  1.73119724e-01,\n",
       "        1.17491186e-03,  7.82191753e-03,  2.35809952e-01, -1.04628503e-03,\n",
       "        3.96862626e-04,  2.35444576e-01,  2.07750782e-01,  2.47894734e-01,\n",
       "        2.10212171e-02,  6.91433251e-03,  2.42081553e-01,  2.39952832e-01,\n",
       "        2.39251256e-01,  1.19313873e-01,  1.51153699e-01,  2.36776099e-01,\n",
       "        6.66461885e-03,  1.79383829e-01,  2.10473359e-01,  2.33734906e-01,\n",
       "        2.10473359e-01,  3.61168385e-02,  2.98810005e-03,  2.38959700e-01,\n",
       "        2.99465716e-01,  2.13998854e-01,  2.41367742e-01,  2.16159165e-01,\n",
       "        2.37244785e-01,  2.50936151e-01,  3.52675766e-02,  2.35082567e-01,\n",
       "        2.60317504e-01,  8.42361823e-02,  2.89842784e-02,  4.15784121e-03,\n",
       "        2.04997629e-01,  1.80872440e-01,  2.35819414e-01,  1.99512213e-01,\n",
       "        1.77907035e-01,  2.46603757e-01,  2.35706955e-01,  2.35122412e-01,\n",
       "        2.44159371e-01,  2.41981924e-01,  2.41711453e-01,  2.80246139e-04,\n",
       "        2.38798305e-01,  2.38613546e-01,  2.57752419e-01,  7.91251659e-05,\n",
       "        1.35599524e-01,  1.25613332e-01,  2.33982146e-01, -1.10217929e-03,\n",
       "        2.40456939e-01,  1.26244724e-02,  1.49879754e-02,  1.50868267e-01,\n",
       "        2.10473359e-01,  2.25535825e-01,  2.49321461e-01,  1.63100690e-01,\n",
       "        1.91339418e-01,  2.35312760e-01,  2.39792317e-01,  2.21729279e-03,\n",
       "        2.19993174e-01,  2.36492932e-01,  8.50021839e-04,  2.27825224e-01,\n",
       "        1.03975236e-02,  1.35833025e-03, -1.88801885e-02,  2.38955006e-01,\n",
       "        2.37596497e-01,  3.14644575e-02,  4.69686091e-03,  2.39064366e-01,\n",
       "        2.36637622e-01,  1.54376209e-01,  1.56024590e-01,  4.04423177e-02,\n",
       "        1.56826824e-02,  5.24803996e-04,  1.90757692e-01,  1.58950076e-01,\n",
       "        2.28515044e-01,  1.66185200e-03,  4.01963294e-03,  2.33537853e-01,\n",
       "        2.39302546e-01,  2.16131449e-01,  2.38432184e-01,  1.58779323e-03,\n",
       "        1.18727043e-01,  2.41477549e-01,  1.56866044e-01,  5.06655872e-03,\n",
       "        1.25959516e-03,  2.37262815e-01,  2.04344288e-01,  2.44023442e-01,\n",
       "        1.90249279e-01,  2.35584319e-01,  2.39631772e-01,  2.30106264e-01,\n",
       "       -1.55003369e-03,  2.32139006e-01,  2.35706955e-01,  2.46237174e-01,\n",
       "        2.11801708e-01,  1.06367022e-02,  1.05233192e-02,  2.34976411e-01,\n",
       "        2.37107575e-01,  2.39204228e-01,  2.38849312e-01,  1.17491186e-03,\n",
       "       -1.67631656e-02,  3.34784389e-04,  9.89286602e-03,  8.79749656e-04,\n",
       "        1.50925279e-01,  2.45456666e-01,  4.64971960e-02,  4.12216485e-02,\n",
       "        2.50824571e-01,  3.76351178e-03, -2.43246704e-02,  1.04892254e-03,\n",
       "        1.89647943e-01,  2.33783811e-01,  2.07222998e-03,  1.15116850e-01,\n",
       "        2.23121643e-01,  9.48458910e-04,  2.16464028e-01,  2.47275651e-01,\n",
       "        3.19968164e-03,  2.31677130e-01,  2.45950118e-01,  1.75994962e-01,\n",
       "       -2.04861164e-03,  2.10359722e-01,  7.70323575e-02,  5.37993014e-03,\n",
       "        2.41128847e-01,  6.90766200e-02,  2.37135276e-01,  2.68396735e-03,\n",
       "        1.47207230e-01,  1.50868267e-01,  1.98280394e-01, -5.80410659e-03,\n",
       "        9.70763639e-02,  1.25060424e-01,  1.86157167e-01,  2.41142049e-01,\n",
       "        7.91251659e-05,  8.45078975e-02, -5.05670905e-04,  1.68198526e-01,\n",
       "       -4.52205539e-04,  3.11532617e-03,  2.36213923e-01,  2.18950212e-03,\n",
       "        1.15757734e-02,  1.86234280e-01,  2.35029340e-01,  9.86272916e-02,\n",
       "        2.20777065e-01,  2.39302546e-01,  5.89103580e-01,  2.33734906e-01,\n",
       "        1.62299603e-01,  1.41865849e-01,  2.20158249e-01,  2.34342247e-01,\n",
       "        1.87405944e-03,  2.34481230e-01,  2.44976535e-01,  1.16792470e-02,\n",
       "        2.38624126e-01,  1.52054727e-02,  4.59844321e-02,  1.64086670e-02,\n",
       "        3.39263678e-03,  2.76445895e-02,  1.28573567e-01,  3.07480991e-03,\n",
       "        1.07443184e-02,  1.23402476e-03,  3.98697257e-02,  2.13333517e-01,\n",
       "        1.64724231e-01,  2.32439965e-01,  2.07635596e-01,  2.31902778e-01,\n",
       "        2.77225673e-03,  2.28813976e-01,  1.20078638e-01,  2.22499520e-01,\n",
       "        1.23699665e-01,  1.98358834e-01,  2.35704139e-01,  2.35809952e-01,\n",
       "        2.36875534e-01,  2.45292068e-01, -2.46600509e-02, -1.40577555e-04,\n",
       "        1.61282718e-02,  9.35469568e-03,  2.48037234e-01,  2.13595629e-01,\n",
       "        2.21851245e-01,  1.37897432e-02,  2.37489790e-01,  6.79812655e-02,\n",
       "        2.40654796e-01, -2.18958408e-02,  3.53762984e-01,  1.76694155e-01,\n",
       "        1.19747221e-03,  1.67918205e-03,  2.40033746e-01,  2.06901401e-01,\n",
       "        2.42240697e-01,  2.73472071e-03,  2.16867268e-01,  1.95048004e-01,\n",
       "        1.84551939e-01,  2.39946067e-01,  1.87259912e-03,  7.92153180e-03,\n",
       "        2.15500414e-01,  1.34523213e-03,  2.50565410e-01,  2.32725203e-01,\n",
       "        2.48020738e-01,  9.17169973e-02,  2.37841025e-01, -1.49439275e-03,\n",
       "        7.94239789e-02,  1.22190051e-01,  1.90638021e-01,  1.56901330e-02,\n",
       "        2.40725935e-01,  2.38689587e-01, -4.13596630e-04,  2.39551604e-01,\n",
       "        1.87517613e-01,  2.39261568e-01,  1.85256541e-01,  3.65122825e-01,\n",
       "        1.19149685e-04, -8.52942467e-05,  1.52627677e-01,  2.38390744e-01,\n",
       "        5.55215329e-02,  1.22584254e-02,  2.36847147e-01,  7.54594803e-04,\n",
       "        2.11892828e-01,  1.44782960e-01,  2.35721409e-01,  2.19647139e-01,\n",
       "        1.62299603e-01,  2.34474152e-01,  2.52393335e-01,  2.45027870e-01,\n",
       "        2.47272432e-01,  2.42432848e-01,  2.36003950e-01,  1.97791532e-01,\n",
       "        2.23121643e-01,  2.11859912e-01,  1.77463889e-03,  2.45565653e-01,\n",
       "        2.31141418e-01,  1.20180480e-01,  2.17527613e-01,  2.20832512e-01,\n",
       "        2.21314833e-01,  5.62737882e-03,  2.43370935e-01,  6.63995743e-03,\n",
       "        3.51945758e-01,  2.35280350e-01,  1.45412982e-03,  5.00805378e-02,\n",
       "        2.03151330e-01,  2.39438951e-01,  9.81554389e-04,  2.37091452e-01,\n",
       "        2.20806450e-01, -2.50604749e-03,  1.03975236e-02,  1.41648352e-02,\n",
       "        2.39334702e-01,  4.90562692e-02,  1.34606838e-01,  2.34038025e-01,\n",
       "        8.44061375e-04,  1.23076014e-01,  1.00041628e-02,  2.46284232e-01,\n",
       "        2.37924099e-01,  1.86842948e-01,  7.84015656e-03,  1.82937086e-03,\n",
       "        5.76300919e-03,  2.41202474e-01,  2.39114150e-01,  2.47505978e-01,\n",
       "        2.33711034e-01,  2.21905947e-01,  2.41765603e-01,  1.92570522e-01,\n",
       "        2.33037740e-01,  5.41399360e-01,  4.51930523e-01,  1.32490695e-03,\n",
       "        1.56866044e-01,  2.39280134e-01,  2.20220059e-01,  1.04872555e-01,\n",
       "        6.50665313e-02,  2.01159447e-01,  2.41787568e-01,  9.97552872e-02,\n",
       "        2.44158506e-01, -2.26010382e-03,  2.36508295e-01,  2.32122391e-01,\n",
       "        4.79817390e-05,  2.35029340e-01,  2.17057407e-01,  2.20892116e-01,\n",
       "        1.18869543e-03,  2.38450155e-01,  1.53120607e-01,  2.37420827e-01,\n",
       "        1.55523270e-02,  2.28891134e-01,  2.40251258e-01,  1.70654804e-01,\n",
       "        1.96681127e-01, -8.31143558e-03,  1.03719532e-03,  1.91995159e-01,\n",
       "        2.12671191e-01,  1.75790370e-01, -1.40577555e-04,  3.71393114e-02,\n",
       "        6.79652393e-03,  3.40625346e-02,  2.67805159e-03,  1.68579787e-01,\n",
       "        7.90009946e-02,  8.99836421e-04,  1.82450682e-01,  1.35424525e-01,\n",
       "        2.17706323e-01,  2.43402719e-01,  2.34742790e-01,  2.36923963e-01,\n",
       "        1.68743208e-01,  2.37420827e-01,  1.76108077e-01,  1.97619244e-01,\n",
       "        1.38049126e-02,  2.33279482e-01,  1.50868267e-01,  2.64024377e-01,\n",
       "        1.30958214e-01,  1.75027445e-01,  1.64054126e-01,  2.35289827e-01,\n",
       "        1.69728965e-01,  1.91604584e-01,  2.22713381e-01,  1.16752088e-03,\n",
       "        2.35325605e-01,  2.33470485e-01,  2.39380881e-01,  5.78586310e-02,\n",
       "        1.23158023e-01,  4.46471944e-02,  2.41141826e-01,  2.35565662e-01,\n",
       "        2.39729881e-04,  1.75994962e-01, -1.30269378e-02,  1.65960193e-03,\n",
       "        2.12323457e-01,  3.93224210e-02, -2.59205699e-04, -2.02315748e-02,\n",
       "        4.35042739e-01,  1.14186108e-03,  2.36724898e-01,  4.52045083e-01,\n",
       "        2.88324684e-01,  2.13333517e-01,  1.71672449e-01,  5.79512179e-01,\n",
       "        2.39803016e-01,  2.16045499e-01,  1.58619195e-01,  2.29513004e-01,\n",
       "       -7.27146864e-04, -2.06872821e-03,  1.98780447e-02,  2.37466946e-01,\n",
       "        9.84355658e-02,  3.23936790e-02,  2.43135273e-01,  2.35443085e-01,\n",
       "        1.83183014e-01,  2.32668087e-01,  1.92271724e-01,  2.41079390e-01,\n",
       "        6.98557124e-02,  2.38689587e-01, -2.07499862e-02,  2.36954331e-01,\n",
       "        2.42764920e-01,  3.55467200e-04,  2.37124339e-01,  1.83647573e-01,\n",
       "        2.19819814e-01,  2.12328732e-01,  2.73472071e-03, -1.91152096e-04,\n",
       "        1.27330288e-01,  4.56306264e-02,  2.26797476e-01,  1.82130754e-01,\n",
       "        1.94393173e-01,  2.44252235e-01,  5.19886613e-04,  2.34621346e-01,\n",
       "        6.23032451e-04,  2.35704139e-01,  6.91562891e-04, -8.39722157e-03,\n",
       "        1.85822099e-01,  2.35839754e-01,  2.35446095e-01,  4.95484471e-03,\n",
       "        1.84655756e-01,  1.04075722e-01,  1.97791532e-01,  8.81632566e-02,\n",
       "        8.61974657e-02,  2.93215960e-01, -2.86831558e-02,  2.37209618e-01,\n",
       "        2.82229751e-01, -6.64398074e-04,  2.43608162e-01,  2.03405291e-01,\n",
       "        2.36822963e-01, -2.01742351e-03,  1.15678906e-01,  2.47603506e-01,\n",
       "        1.53238490e-01,  2.47505978e-01,  2.39587292e-01,  7.32372850e-02,\n",
       "        2.33338714e-01,  7.70323575e-02,  6.00424409e-03,  5.91024756e-03,\n",
       "        2.36674279e-01,  2.44217902e-01,  2.38334507e-01,  1.85688496e-01,\n",
       "        2.37039179e-01,  8.33958387e-04,  2.43999034e-01,  2.41454870e-01,\n",
       "        5.68004996e-02,  2.47915015e-01,  2.43326828e-01,  2.48511061e-01,\n",
       "        2.41573602e-01,  6.23458624e-03,  2.34628707e-01,  1.28553808e-03,\n",
       "       -7.67721236e-03,  2.42315322e-01,  2.47272432e-01,  8.21224973e-02,\n",
       "        2.06429631e-01,  1.09541968e-01,  2.41926461e-01,  9.02363881e-02,\n",
       "        1.86022490e-01,  1.82284713e-01,  2.41793543e-01,  5.41578233e-03,\n",
       "        2.36672401e-01,  2.34871522e-01,  2.33400434e-01,  2.36018240e-01,\n",
       "        7.92571902e-03,  1.51153699e-01,  4.82178032e-02,  2.39732593e-01,\n",
       "        4.92900610e-04,  7.74174929e-04,  2.41101503e-01, -1.23333931e-03,\n",
       "        2.23162770e-03,  2.36074269e-01,  2.46043265e-01,  1.97994292e-01,\n",
       "        1.94752216e-03,  2.27039367e-01,  1.94280922e-01,  2.13416338e-01,\n",
       "        2.55011141e-01,  1.87098160e-01,  2.36853957e-01,  3.62101346e-02,\n",
       "        5.02020121e-05,  2.14591011e-01,  2.38413721e-01,  2.44096637e-01,\n",
       "        9.14770365e-03,  2.23055720e-01,  2.43691340e-01,  2.37027302e-01,\n",
       "        2.23162770e-03,  7.16298819e-04,  2.38214374e-01,  2.42977113e-01,\n",
       "        2.19688728e-01,  5.55215329e-02,  2.86392570e-02,  2.30148494e-01,\n",
       "        2.37763330e-01, -1.81145519e-02,  2.36199841e-01,  2.57254332e-01,\n",
       "        2.54529089e-01,  1.17724352e-01,  2.24953890e-03,  1.20939121e-01,\n",
       "        1.50411293e-01,  2.40810812e-01,  3.59071791e-03, -8.44460726e-03,\n",
       "        1.97758704e-01,  2.36169040e-01,  2.17825145e-01,  2.32725203e-01,\n",
       "        2.40323752e-01,  2.14023203e-01,  1.82630330e-01,  2.38968164e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train_pred[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b9a98195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Water saturation at t = 0')\n",
    "plt.scatter(np.linspace(0.0, 1.0, nx0), swat[:, 0, 0, -1], label='Simulator')\n",
    "plt.scatter(np.linspace(0.0, 1.0, nx0), model_prediction[:, 2].reshape(nx0, nx1, nx2)[:, 0, 0], label='PINN')\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.savefig('swat_scatter_pinn.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Pressure at t = 0')\n",
    "plt.scatter(np.linspace(0.0, 1.0, nx0), pres[:, 0, 0, -1], label='Simulator')\n",
    "plt.scatter(np.linspace(0.0, 1.0, nx0), model_prediction[:, 0].reshape(nx0, nx1, nx2)[:, 0, 0], label='PINN')\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.savefig('pres_scatter_pinn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe7f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_3.11",
   "language": "python",
   "name": "kernel_3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
